
@doc raw"""
    Tucker{N, R, D, ùîΩ} <: AbstractManifold{ùîΩ}

The manifold of ``N_1 \times \dots \times N_D`` real-valued or complex-valued tensors of
fixed multilinear rank ``(R_1, \dots, R_D)`` . If ``R_1 = \dots = R_D = 1``, this is the
Segre manifold, i.e., the set of rank-1 tensors.

# Representation in HOSVD format

Let ``\mathbb{F}`` be the real or complex numbers.
Any tensor ``p`` on the Tucker manifold can be represented as a multilinear product in HOSVD
[DeLathauwerDeMoorVanderwalle:2000](@cite) form
```math
p = (U_1,\dots,U_D) \cdot \mathcal{C}
```
where ``\mathcal C \in \mathbb{F}^{R_1 \times \dots \times R_D}`` and, for ``d=1,\dots,D``,
the matrix ``U_d \in \mathbb{F}^{N_d \times R_d}`` contains the singular vectors of the
``d``th unfolding of ``\mathcal{A}``

# Tangent space

The tangent space to the Tucker manifold at
``p = (U_1,\dots,U_D) \cdot \mathcal{C}`` is [KochLubich:2010](@cite)
```math
T_p \mathcal{M} =
\bigl\{
(U_1,\dots,U_D) \cdot \mathcal{C}^\prime
+ \sum_{d=1}^D \bigl(
    (U_1, \dots, U_{d-1}, U_d^\prime, U_{d+1}, \dots, U_D)
    \cdot \mathcal{C}
\bigr)
\bigr\}
```
where ``\mathcal{C}^\prime`` is arbitrary, ``U_d^{\mathrm{H}}`` is the Hermitian adjoint of
``U_d``, and ``U_d^{\mathrm{H}} U_d^\prime = 0`` for all ``d``.

# Constructor
    Tucker(N::NTuple{D, Int}, R::NTuple{D, Int}[, field = ‚Ñù])

Generate the manifold of `field`-valued tensors of dimensions  `N[1] √ó ‚Ä¶ √ó N[D]` and
multilinear rank `R = (R[1], ‚Ä¶, R[D])`.
"""
struct Tucker{N,R,D,ùîΩ} <: AbstractManifold{ùîΩ} end
function Tucker(n‚Éó::NTuple{D,Int}, r‚Éó::NTuple{D,Int}, field::AbstractNumbers=‚Ñù) where {D}
    @assert is_valid_mlrank(n‚Éó, r‚Éó)
    return Tucker{n‚Éó,r‚Éó,D,field}()
end

#=
HOSVD{T, D}

Higher-order singular value decomposition of an order D tensor with eltype T
fields:
* U: singular vectors of the unfoldings
* core: core tensor
* œÉ : singular values of the unfoldings
=#
struct HOSVD{T,D}
    U::NTuple{D,Matrix{T}}
    core::Array{T,D}
    œÉ::NTuple{D,Vector{T}}
end

@doc raw"""
    TuckerPoint{T,D}

An order `D` tensor of fixed multilinear rank and entries of type `T`, which makes it a
point on the [`Tucker`](@ref) manifold. The tensor is represented in HOSVD form.

# Constructors:
    TuckerPoint(core::AbstractArray{T,D}, factors::Vararg{<:AbstractMatrix{T},D}) where {T,D}

Construct an order `D` tensor of element type `T` that can be represented as the
multilinear product `(factors[1], ‚Ä¶, factors[D]) ‚ãÖ core`.
It is assumed that the dimensions of the core are the multilinear
rank of the tensor and that the matrices `factors` each have full rank. No further
assumptions are made.

    TuckerPoint(p::AbstractArray{T,D}, mlrank::NTuple{D,Int}) where {T,D}

The low-multilinear rank tensor arising from the sequentially truncated the higher-order
singular value decomposition of the `D`-dimensional array `p` of type `T`. The singular
values are truncated to get a multilinear rank `mlrank`
[VannieuwenhovenVanderbrilMeerbergen:2012](@cite).
"""
struct TuckerPoint{T,D} <: AbstractManifoldPoint
    hosvd::HOSVD{T,D}
end
function TuckerPoint(
    core::AbstractArray{T,D},
    factors::Vararg{MtxT,D},
) where {T,D,MtxT<:AbstractMatrix{T}}
    # Take the QR decompositions of the factors and multiply the R factors into the core
    qrfacs = qr.(factors)
    Q = map(qrfac -> qrfac.Q, qrfacs)
    R = map(qrfac -> qrfac.R, qrfacs)
    core‚Ä≤ = reshape(Kronecker.:‚äó(reverse(R)...) * vec(core), size(core))

    # Convert to HOSVD format by taking the HOSVD of the core
    decomp = st_hosvd(core‚Ä≤)
    factors‚Ä≤ = Q .* decomp.U
    return TuckerPoint(HOSVD{T,D}(factors‚Ä≤, decomp.core, decomp.œÉ))
end
function TuckerPoint(A::AbstractArray{T,D}, mlrank::NTuple{D,Int}) where {T,D}
    @assert is_valid_mlrank(size(A), mlrank)
    return TuckerPoint(st_hosvd(A, mlrank))
end

@doc raw"""
    TuckerTVector{T, D} <: TVector

Tangent vector to the `D`-th order [`Tucker`](@ref) manifold at
``p = (U_1,\dots,U_D) ‚ãÖ \mathcal{C}``. The numbers are of type `T` and the vector is
represented as
````math
X =
(U_1,\dots,U_D) \cdot \mathcal{C}^\prime +
\sum_{d=1}^D (U_1,\dots,U_{d-1},U_d^\prime,U_{d+1},\dots,U_D) \cdot \mathcal{C}
````
where ``U_d^\mathrm{H} U_d^\prime = 0``.

# Constructor
    TuckerTVector(C‚Ä≤::Array{T,D}, U‚Ä≤::NTuple{D,Matrix{T}}) where {T,D}

Constructs a `D`th order [`TuckerTVector`](@ref) of number type `T` with ``C^\prime``
and ``U^\prime``, so that, together with a
[`TuckerPoint`](@ref) ``p`` as above, the tangent vector can be represented as ``X`` in the
above expression.
"""
struct TuckerTVector{T,D} <: TVector
    CÃá::Array{T,D}
    UÃá::NTuple{D,Matrix{T}}
end

# An implicitly stored basis of the tangent space to the Tucker manifold. This is the basis
# from [Dewaele2021] and acts as the default orthonormal basis.
struct HOSVDBasis{T,D}
    point::TuckerPoint{T,D}
    U‚ä•::NTuple{D,Matrix{T}}
end
CachedHOSVDBasis{ùîΩ,T,D} =
    CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ,TangentSpaceType},HOSVDBasis{T,D}}

‚äó·¥ø(a...) = Kronecker.:‚äó(reverse(a)...)

Base.:*(s::Number, x::TuckerTVector) = TuckerTVector(s * x.CÃá, s .* x.UÃá)
Base.:*(x::TuckerTVector, s::Number) = TuckerTVector(x.CÃá * s, x.UÃá .* s)
Base.:/(x::TuckerTVector, s::Number) = TuckerTVector(x.CÃá / s, x.UÃá ./ s)
Base.:\(s::Number, x::TuckerTVector) = TuckerTVector(s \ x.CÃá, s .\ x.UÃá)
Base.:+(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÃá + y.CÃá, x.UÃá .+ y.UÃá)
Base.:-(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÃá - y.CÃá, x.UÃá .- y.UÃá)
Base.:-(x::TuckerTVector) = TuckerTVector(-x.CÃá, map(-, x.UÃá))
Base.:+(x::TuckerTVector) = TuckerTVector(x.CÃá, x.UÃá)
Base.:(==)(x::TuckerTVector, y::TuckerTVector) = (x.CÃá == y.CÃá) && all(x.UÃá .== y.UÃá)

allocate(p::TuckerPoint) = allocate(p, number_eltype(p))
function allocate(p::TuckerPoint{Tp,D}, ::Type{T}) where {T,Tp,D}
    @assert promote_type(Tp, T) == T
    return TuckerPoint(
        HOSVD(allocate(p.hosvd.U, T), allocate(p.hosvd.core, T), allocate(p.hosvd.œÉ, T)),
    )
end
allocate(x::TuckerTVector) = allocate(x, number_eltype(x))
function allocate(x::TuckerTVector, ::Type{T}) where {T}
    return TuckerTVector(allocate(x.CÃá, T), allocate(x.UÃá, T))
end

# Tuple-like broadcasting of TuckerTVector
Base.axes(::TuckerTVector) = ()

function Broadcast.BroadcastStyle(::Type{TuckerTVector{T,D}}) where {T,D}
    return Broadcast.Style{TuckerTVector{Any,D}}()
end
function Broadcast.BroadcastStyle(
    ::Broadcast.AbstractArrayStyle{0},
    b::Broadcast.Style{<:TuckerTVector},
)
    return b
end

function Broadcast.instantiate(
    bc::Broadcast.Broadcasted{Broadcast.Style{TuckerTVector{Any,D}},Nothing},
) where {D}
    return bc
end
function Broadcast.instantiate(
    bc::Broadcast.Broadcasted{Broadcast.Style{TuckerTVector{Any,D}}},
) where {D}
    Broadcast.check_broadcast_axes(bc.axes, bc.args...)
    return bc
end

Broadcast.broadcastable(v::TuckerTVector) = v

Base.@propagate_inbounds function Broadcast._broadcast_getindex(
    v::TuckerTVector,
    ::Val{I},
) where {I}
    if I isa Symbol
        return getfield(v, I)
    else
        return getfield(v, I[1])[I[2]]
    end
end

####

@doc raw"""
    check_point(M::Tucker{N,R,D}, p; kwargs...) where {N,R,D}

Check whether the multidimensional array or [`TuckerPoint`](@ref) `p` is a point on the
[`Tucker`](@ref) manifold, i.e. it is a `D`th order `N[1] √ó ‚Ä¶ √ó N[D]` tensor of multilinear
rank `(R[1], ‚Ä¶, R[D])`. The keyword arguments are passed to the matrix rank function applied
to the unfoldings.
For a [`TuckerPoint`](@ref) it is checked that the point is in correct HOSVD form.
"""
function check_point(M::Tucker{N,R,D}, x; kwargs...) where {N,R,D}
    s = "The point $(x) does not lie on $(M), "
    size(x) == N || return DomainError(size(x), s * "since its size is not $(N).")
    x_buffer = similar(x)
    for d in 1:ndims(x)
        r = rank(tensor_unfold!(x_buffer, x, d); kwargs...)
        r == R[d] || return DomainError(size(x), s * "since its rank is not $(R).")
    end
    return nothing
end
function check_point(M::Tucker{N,R,D}, x::TuckerPoint; kwargs...) where {N,R,D}
    s = "The point $(x) does not lie on $(M), "
    U = x.hosvd.U
    ‚Ñ≠ = x.hosvd.core
    if size(‚Ñ≠) ‚â† R
        return DomainError(
            size(x.hosvd.core),
            s * "since the size of the core is not $(R).",
        )
    end
    if size(x) ‚â† N
        return DomainError(size(x), s * "since its dimensions are not $(N).")
    end
    for u in U
        if u' * u ‚ââ LinearAlgebra.I
            return DomainError(
                norm(u' * u - LinearAlgebra.I),
                s * "since its factor matrices are not unitary.",
            )
        end
    end
    ‚Ñ≠_buffer = similar(‚Ñ≠)
    for d in 1:ndims(x.hosvd.core)
        ‚Ñ≠‚ÅΩ·µà‚Åæ = tensor_unfold!(‚Ñ≠_buffer, ‚Ñ≠, d)
        gram = ‚Ñ≠‚ÅΩ·µà‚Åæ * ‚Ñ≠‚ÅΩ·µà‚Åæ'
        if gram ‚ââ Diagonal(x.hosvd.œÉ[d])^2
            return DomainError(
                norm(gram - Diagonal(x.hosvd.œÉ[d])^2),
                s *
                "since the unfoldings of the core are not diagonalised by" *
                "the singular values.",
            )
        end
        if rank(Diagonal(x.hosvd.œÉ[d]); kwargs...) ‚â† R[d]
            return DomainError(
                minimum(x.hosvd.œÉ[d]),
                s * "since the core does not have full multilinear rank.",
            )
        end
    end
    return nothing
end

@doc raw"""
    check_vector(M::Tucker{N,R,D}, p::TuckerPoint{T,D}, X::TuckerTVector) where {N,R,T,D}

Check whether a [`TuckerTVector`](@ref) `X` is is in the tangent space to
the `D`th order [`Tucker`](@ref) manifold `M` at the `D`th order [`TuckerPoint`](@ref) `p`.
This
is the case when the dimensions of the factors in `X` agree with those of `p` and the factor
matrices of `X` are in the orthogonal complement of the HOSVD factors of `p`.
"""
function check_vector(
    M::Tucker{N,R,D},
    p::TuckerPoint{T,D},
    v::TuckerTVector,
) where {N,R,T,D}
    s = "The tangent vector $(v) is not a tangent vector to $(p) on $(M), "
    if size(p.hosvd.core) ‚â† size(v.CÃá) || any(size.(v.UÃá) .‚â† size.(p.hosvd.U))
        return DomainError(
            size(v.CÃá),
            s * "since the array dimensons of $(p) and $(v)" * "do not agree.",
        )
    end
    for (U, UÃá) in zip(p.hosvd.U, v.UÃá)
        if norm(U' * UÃá) ‚â• ‚àöeps(eltype(U)) * ‚àölength(U)
            return DomainError(
                norm(U' * UÃá),
                s *
                "since the columns of x.hosvd.U are not" *
                "orthogonal to those of v.UÃá.",
            )
        end
    end
    return nothing
end

"""
    Base.convert(::Type{Matrix{T}}, basis::CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ, TangentSpaceType},HOSVDBasis{T, D}}) where {ùîΩ, T, D}
    Base.convert(::Type{Matrix}, basis::CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ, TangentSpaceType},HOSVDBasis{T, D}}) where {ùîΩ, T, D}

Convert a HOSVD-derived cached basis from [DewaeleBreidingVannieuwenhoven:2021](@cite) of the `D`th order
[`Tucker`](@ref) manifold with number type `T` to a matrix.
The columns of this matrix are the vectorisations of the
[`embed`](@ref)dings of the basis vectors.
"""
function Base.convert(::Type{Matrix{T}}, ‚Ñ¨::CachedHOSVDBasis{ùîΩ,T,D}) where {ùîΩ,T,D}
    ùîÑ = ‚Ñ¨.data.point
    r‚Éó = size(ùîÑ.hosvd.core)
    n‚Éó = size(ùîÑ)
    ‚Ñ≥ = Tucker(n‚Éó, r‚Éó)

    J = Matrix{T}(undef, prod(n‚Éó), manifold_dimension(‚Ñ≥))
    # compute all possible ‚àÇùîÑ‚ï±‚àÇ‚Ñ≠ (in one go is quicker than one vector at a time)
    J[:, 1:prod(r‚Éó)] = ‚äó·¥ø(ùîÑ.hosvd.U...)
    # compute all possible ‚àÇùîÑ‚ï±‚àÇU[d] for d = 1,...,D
    function fill_column!(i, v·µ¢)
        J·µ¢_tensor = reshape(view(J, :, i), n‚Éó) # changes to this apply to J as well
        return embed!(‚Ñ≥, J·µ¢_tensor, ùîÑ, v·µ¢)
    end
    foreach(fill_column!, ‚Ñ≥, ùîÑ, ‚Ñ¨, (prod(r‚Éó) + 1):manifold_dimension(‚Ñ≥))
    return J
end
function Base.convert(::Type{Matrix}, basis::CachedHOSVDBasis{ùîΩ,T,D}) where {ùîΩ,T,D}
    return convert(Matrix{T}, basis)
end

@inline function Base.copy(
    bc::Broadcast.Broadcasted{Broadcast.Style{TuckerTVector{Any,D}}},
) where {D}
    return TuckerTVector(
        @inbounds(Broadcast._broadcast_getindex(bc, Val(:CÃá))),
        ntuple(i -> @inbounds(Broadcast._broadcast_getindex(bc, Val((:UÃá, i)))), Val(D)),
    )
end
Base.copy(x::TuckerTVector) = TuckerTVector(copy(x.CÃá), map(copy, x.UÃá))

function Base.copyto!(q::TuckerPoint, p::TuckerPoint)
    for d in 1:ndims(q)
        copyto!(q.hosvd.U[d], p.hosvd.U[d])
        copyto!(q.hosvd.œÉ[d], p.hosvd.œÉ[d])
    end
    copyto!(q.hosvd.core, p.hosvd.core)
    return q
end
function Base.copyto!(y::TuckerTVector, x::TuckerTVector)
    for d in 1:ndims(y.CÃá)
        copyto!(y.UÃá[d], x.UÃá[d])
    end
    copyto!(y.CÃá, x.CÃá)
    return y
end
@inline function Base.copyto!(
    dest::TuckerTVector,
    bc::Broadcast.Broadcasted{Broadcast.Style{TuckerTVector{Any,D}}},
) where {D}
    # Performance optimization: broadcast!(identity, dest, A) is equivalent to copyto!(dest, A) if indices match
    if bc.f === identity && bc.args isa Tuple{TuckerTVector} # only a single input argument to broadcast!
        A = bc.args[1]
        return copyto!(dest, A)
    end
    bc‚Ä≤ = Broadcast.preprocess(dest, bc)
    copyto!(dest.CÃá, Broadcast._broadcast_getindex(bc‚Ä≤, Val(:CÃá)))
    for i in 1:D
        copyto!(dest.UÃá[i], Broadcast._broadcast_getindex(bc, Val((:UÃá, i))))
    end
    return dest
end

@doc raw"""
    embed(::Tucker{N,R,D}, p::TuckerPoint) where {N,R,D}

Convert a [`TuckerPoint`](@ref) `p` on the rank `R` [`Tucker`](@ref) manifold to a full
`N[1] √ó ‚Ä¶ √ó N[D]`-array by evaluating the Tucker decomposition.

    embed(::Tucker{N,R,D}, p::TuckerPoint, X::TuckerTVector) where {N,R,D}

Convert a tangent vector `X` with base point `p` on the rank `R` [`Tucker`](@ref)
manifold to a full tensor, represented as an `N[1] √ó ‚Ä¶ √ó N[D]`-array.
"""
embed(::Tucker, ::Any, ::TuckerPoint)

function embed!(::Tucker, q, p::TuckerPoint)
    return copyto!(q, reshape(‚äó·¥ø(p.hosvd.U...) * vec(p.hosvd.core), size(p)))
end
function embed!(‚Ñ≥::Tucker, Y, ùîÑ::TuckerPoint{T,D}, X::TuckerTVector) where {T,D}
    mul!(vec(Y), ‚äó·¥ø(ùîÑ.hosvd.U...), vec(X.CÃá))
    ùîÑ_embedded = embed(‚Ñ≥, ùîÑ)
    buffer = similar(ùîÑ_embedded)
    for k in 1:D
        UÃá‚ÇñU‚Çñ·µÄùîÑ‚Çç‚Çñ‚Çé = X.UÃá[k] * (ùîÑ.hosvd.U[k]' * tensor_unfold!(buffer, ùîÑ_embedded, k))
        Y .= Y + tensor_fold!(buffer, UÃá‚ÇñU‚Çñ·µÄùîÑ‚Çç‚Çñ‚Çé, k)
    end
    return Y
end

@doc raw"""
    Base.foreach(f, M::Tucker, p::TuckerPoint, basis::AbstractBasis, indices=1:manifold_dimension(M))

Let `basis` be and [`AbstractBasis`](https://juliamanifolds.github.io/ManifoldsBase.jl/stable/bases.html#ManifoldsBase.AbstractBasis) at a point `p` on `M`. Suppose `f` is a function
that takes an index and a vector as an argument.
This function applies `f` to `i` and the `i`th basis vector sequentially for each `i` in
`indices`.
Using a [`CachedBasis`](https://juliamanifolds.github.io/ManifoldsBase.jl/stable/bases.html#ManifoldsBase.CachedBasis) may speed up the computation.

**NOTE**: The i'th basis vector is overwritten in each iteration. If any information about
the vector is to be stored, `f` must make a copy.
"""
function Base.foreach(
    f,
    M::Tucker,
    p::TuckerPoint,
    basis::AbstractBasis,
    indices=1:manifold_dimension(M),
)
    # Use in-place variants to avoid superfluous allocation
    b·µ¢ = zero_vector(M, p)
    e·µ¢ = zeros(number_eltype(p), manifold_dimension(M))
    for i in indices
        e·µ¢[i] = one(eltype(e·µ¢))
        get_vector!(M, b·µ¢, p, e·µ¢, basis)
        e·µ¢[i] = zero(eltype(e·µ¢))
        f(i, b·µ¢)
    end
end

@doc raw"""
    get_basis(:: Tucker, p::TuckerPoint, basisType::DefaultOrthonormalBasis{ùîΩ, TangentSpaceType}) where ùîΩ

An implicitly stored basis of the tangent space to the Tucker manifold.
Assume ``p = (U_1,\dots,U_D) \cdot \mathcal{C}`` is in HOSVD format and that, for
``d=1,\dots,D``, the singular values of the
``d``'th unfolding are ``\sigma_{dj}``, with ``j = 1,\dots,R_d``.
The basis of the tangent space is as follows: [DewaeleBreidingVannieuwenhoven:2021](@cite)

````math
\bigl\{
(U_1,\dots,U_D) e_i
\bigr\} \cup \bigl\{
(U_1,\dots, \sigma_{dj}^{-1} U_d^{\perp} e_i e_j^T,\dots,U_D) \cdot \mathcal{C}
\bigr\}
````

for all ``d = 1,\dots,D`` and all canonical basis vectors ``e_i`` and ``e_j``.
Every ``U_d^\perp`` is such that ``[U_d \quad U_d^{\perp}]`` forms an orthonormal basis
of ``\mathbb{R}^{N_d}``.
"""
function get_basis(
    ::Tucker,
    ùîÑ::TuckerPoint,
    basisType::DefaultOrthonormalBasis{ùîΩ,TangentSpaceType}=DefaultOrthonormalBasis(),
) where {ùîΩ}
    D = ndims(ùîÑ)
    n‚Éó = size(ùîÑ)
    r‚Éó = size(ùîÑ.hosvd.core)
    U = ùîÑ.hosvd.U
    U‚ä• = ntuple(d -> Matrix(qr(I - U[d] * U[d]', Val(true)).Q)[:, 1:(n‚Éó[d] - r‚Éó[d])], D)
    basis = HOSVDBasis(ùîÑ, U‚ä•)
    return CachedBasis(basisType, basis)
end

#=
get_coordinates(::Tucker, A, X::TuckerTVector, b)

The coordinates of a tangent vector X at point A on the Tucker manifold with respect to the
basis b.
=#
function get_coordinates(::Tucker, ùîÑ, X::TuckerTVector, ‚Ñ¨::CachedHOSVDBasis)
    coords = vec(X.CÃá)
    for d in 1:length(X.UÃá)
        coord_mtx = (‚Ñ¨.data.U‚ä•[d] \ X.UÃá[d]) * Diagonal(ùîÑ.hosvd.œÉ[d])
        coords = vcat(coords, vec(coord_mtx'))
    end
    return coords
end
function get_coordinates(
    M::Tucker,
    ùîÑ,
    X,
    ‚Ñ¨::DefaultOrthonormalBasis{ùîΩ,TangentSpaceType},
) where {ùîΩ}
    return get_coordinates(M, ùîÑ, X, get_basis(M, ùîÑ, ‚Ñ¨))
end

#=
get_vector(::Tucker, A, x, b)

The tangent vector at a point A whose coordinates with respect to the basis b are x.
=#
function get_vector!(
    ::Tucker,
    y,
    ùîÑ::TuckerPoint,
    x::AbstractVector{T},
    ‚Ñ¨::CachedHOSVDBasis,
) where {T}
    Œæ = convert(Vector{promote_type(number_eltype(ùîÑ), eltype(x))}, x)
    ‚Ñ≠ = ùîÑ.hosvd.core
    œÉ = ùîÑ.hosvd.œÉ
    U‚ä• = ‚Ñ¨.data.U‚ä•
    D = ndims(‚Ñ≠)
    r‚Éó = size(‚Ñ≠)
    n‚Éó = size(ùîÑ)

    # split Œæ into Œæ_core and ŒæU so that vcat(Œæ_core, ŒæU...) == Œæ, but avoid copying
    Œæ_core = view(Œæ, 1:length(‚Ñ≠))
    ŒæU = Vector{typeof(Œæ_core)}(undef, D)
    nextcolumn = length(‚Ñ≠) + 1
    for d in 1:D
        numcols = r‚Éó[d] * (n‚Éó[d] - r‚Éó[d])
        ŒæU[d] = view(Œæ, nextcolumn:(nextcolumn + numcols - 1))
        nextcolumn += numcols
    end

    # Construct ‚àÇU[d] by plugging in the definition of the orthonormal basis [Dewaele2021]
    # ‚àÇU[d] = ‚àë·µ¢‚±º { ŒæU[d]·µ¢‚±º (œÉ[d]‚±º)‚Åª¬π U‚ä•[d] ùêû·µ¢ ùêû‚±º·µÄ }
    #       = U‚ä•[d] * ‚àë‚±º (œÉ[d]‚±º)‚Åª¬π (‚àë·µ¢ ŒæU[d]·µ¢‚±º  ùêû·µ¢) ùêû‚±º·µÄ
    # ŒæU[d] = [Œæ‚ÇÅ‚ÇÅ, ..., Œæ‚ÇÅ‚±º, ..., Œæ·µ¢‚ÇÅ, ..., Œæ·µ¢‚±º, ..., ]
    # => turn these i and j into matrix indices and do matrix operations
    for d in 1:D
        grid = transpose(reshape(ŒæU[d], r‚Éó[d], n‚Éó[d] - r‚Éó[d]))
        mul!(y.UÃá[d], U‚ä•[d], grid * Diagonal(1 ./ œÉ[d]))
    end

    y.CÃá .= reshape(Œæ_core, size(y.CÃá))
    return y
end
function get_vector!(
    ‚Ñ≥::Tucker,
    y,
    ùîÑ::TuckerPoint,
    x,
    ‚Ñ¨::DefaultOrthonormalBasis{ùîΩ,TangentSpaceType},
) where {ùîΩ}
    return get_vector!(‚Ñ≥, y, ùîÑ, x, get_basis(‚Ñ≥, ùîÑ, ‚Ñ¨))
end

function get_vectors(‚Ñ≥::Tucker, ùîÑ::TuckerPoint{T,D}, ‚Ñ¨::CachedHOSVDBasis) where {T,D}
    vectors = Vector{TuckerTVector{T,D}}(undef, manifold_dimension(‚Ñ≥))
    foreach((i, v·µ¢) -> setindex!(vectors, copy(v·µ¢), i), ‚Ñ≥, ùîÑ, ‚Ñ¨)
    return vectors
end
function get_vectors(‚Ñ≥::Tucker, ùîÑ::TuckerPoint, ‚Ñ¨::DefaultOrthonormalBasis)
    return get_vectors(‚Ñ≥, ùîÑ, get_basis(‚Ñ≥, ùîÑ, ‚Ñ¨))
end

"""
    inner(M::Tucker, p::TuckerPoint, X::TuckerTVector, Y::TuckerTVector)

The Euclidean inner product between tangent vectors `X` and `X` at the point `p` on
the Tucker manifold. This is equal to `embed(M, p, X) ‚ãÖ embed(M, p, Y)`.

    inner(::Tucker, A::TuckerPoint, X::TuckerTVector, Y)
    inner(::Tucker, A::TuckerPoint, X, Y::TuckerTVector)

The Euclidean inner product between `X` and `Y` where `X` is a vector tangent to the Tucker
manifold at `p` and `Y` is a vector in the ambient space or vice versa. The vector in the
ambient space is represented as a full tensor, i.e., a multidimensional array.
"""
function inner(::Tucker, ùîÑ::TuckerPoint, x::TuckerTVector, y::TuckerTVector)
    ‚Ñ≠ = ùîÑ.hosvd.core
    dotprod = dot(x.CÃá, y.CÃá)
    ‚Ñ≠_buffer = similar(‚Ñ≠)
    for k in 1:ndims(ùîÑ)
        ‚Ñ≠‚Çç‚Çñ‚Çé = tensor_unfold!(‚Ñ≠_buffer, ‚Ñ≠, k)
        dotprod += dot(x.UÃá[k] * ‚Ñ≠‚Çç‚Çñ‚Çé, y.UÃá[k] * ‚Ñ≠‚Çç‚Çñ‚Çé)
    end
    return dotprod
end
inner(M::Tucker, ùîÑ::TuckerPoint, x::TuckerTVector, y) = dot(embed(M, ùîÑ, x), y)
inner(M::Tucker, ùîÑ::TuckerPoint, x, y::TuckerTVector) = dot(x, embed(M, ùîÑ, y))

"""
    inverse_retract(M::Tucker, p::TuckerPoint, q::TuckerPoint, ::ProjectionInverseRetraction)

The projection inverse retraction on the Tucker manifold interprets `q` as a point in the
ambient Euclidean space (see [`embed`](@ref)) and projects it onto the tangent space at
to `M` at `p`.
"""
inverse_retract(
    ::Tucker,
    ::Any,
    ::TuckerPoint,
    ::TuckerPoint,
    ::ProjectionInverseRetraction,
)

function inverse_retract_project!(‚Ñ≥::Tucker, X, ùîÑ::TuckerPoint, ùîÖ::TuckerPoint)
    diffVector = embed(‚Ñ≥, ùîÖ) - embed(‚Ñ≥, ùîÑ)
    return project!(‚Ñ≥, X, ùîÑ, diffVector)
end

function isapprox(p::TuckerPoint, q::TuckerPoint; kwargs...)
    ‚Ñ≥ = Tucker(size(p), size(p.hosvd.core))
    return isapprox(embed(‚Ñ≥, p), embed(‚Ñ≥, q); kwargs...)
end
isapprox(::Tucker, p::TuckerPoint, q::TuckerPoint; kwargs...) = isapprox(p, q; kwargs...)
function _isapprox(M::Tucker, p::TuckerPoint, x::TuckerTVector, y::TuckerTVector; kwargs...)
    return isapprox(embed(M, p, x), embed(M, p, y); kwargs...)
end

"""
    is_flat(::Tucker)

Return false. [`Tucker`](@ref) is not a flat manifold.
"""
is_flat(M::Tucker) = false

#=
Determines whether there are tensors of dimensions n‚Éó with multilinear rank r‚Éó
=#
function is_valid_mlrank(n‚Éó, r‚Éó)
    return all(r‚Éó .‚â• 1) &&
           all(r‚Éó .‚â§ n‚Éó) &&
           all(ntuple(i -> r‚Éó[i] ‚â§ prod(r‚Éó) √∑ r‚Éó[i], length(r‚Éó)))
end

@doc raw"""
    manifold_dimension(::Tucker{N,R,D}) where {N,R,D}

The dimension of the manifold of ``N_1 \times \dots \times N_D`` tensors of multilinear
rank ``(R_1, \dots, R_D)``, i.e.
````math
\mathrm{dim}(\mathcal{M}) = \prod_{d=1}^D R_d + \sum_{d=1}^D R_d (N_d - R_d).
````
"""
manifold_dimension(::Tucker{n‚Éó,r‚Éó}) where {n‚Éó,r‚Éó} = prod(r‚Éó) + sum(r‚Éó .* (n‚Éó .- r‚Éó))

@doc raw"""
    Base.ndims(p::TuckerPoint{T,D}) where {T,D}

The order of the tensor corresponding to the [`TuckerPoint`](@ref) `p`, i.e., `D`.
"""
Base.ndims(::TuckerPoint{T,D}) where {T,D} = D

number_eltype(::TuckerPoint{T,D}) where {T,D} = T
number_eltype(::TuckerTVector{T,D}) where {T,D} = T

"""
    project(M::Tucker, p::TuckerPoint, X)

The least-squares projection of a dense tensor `X` onto the tangent space to `M` at `p`.
"""
project(::Tucker, ::Any, ::TuckerPoint, ::Any)

function project!(‚Ñ≥::Tucker, Y, ùîÑ::TuckerPoint, X)
    ‚Ñ¨ = get_basis(‚Ñ≥, ùîÑ, DefaultOrthonormalBasis())
    coords = Vector{number_eltype(ùîÑ)}(undef, manifold_dimension(‚Ñ≥))
    f!(i, ‚Ñ¨·µ¢) = setindex!(coords, inner(‚Ñ≥, ùîÑ, ‚Ñ¨·µ¢, X), i)
    foreach(f!, ‚Ñ≥, ùîÑ, ‚Ñ¨)
    return get_vector!(‚Ñ≥, Y, ùîÑ, coords, ‚Ñ¨)
end

@doc raw"""
    retract(::Tucker, p::TuckerPoint, X::TuckerTVector, ::PolarRetraction)

The truncated HOSVD-based retraction [KressnerSteinlechnerVandereycken:2013](@cite) to the Tucker manifold, i.e.
the result is the sequentially tuncated HOSVD approximation of ``p + X``.

In the exceptional case that the multilinear rank of ``p + X`` is lower than that of ``p``, this
retraction produces a boundary point, which is outside the manifold.
"""
retract(::Tucker, ::Any, ::Any, ::PolarRetraction)

function retract_polar!(
    ::Tucker,
    q::TuckerPoint,
    p::TuckerPoint{T,D},
    x::TuckerTVector,
    t::Number,
) where {T,D}
    tx = t * x
    U = p.hosvd.U
    V = tx.UÃá
    ‚Ñ≠ = p.hosvd.core
    ùîä = tx.CÃá
    r‚Éó = size(‚Ñ≠)

    # Build the core tensor S and the factors [U·µà  V·µà]
    S = zeros(T, 2 .* size(‚Ñ≠))
    S[CartesianIndices(‚Ñ≠)] = ‚Ñ≠ + ùîä
    UQ = Matrix{T}[]
    buffer = similar(‚Ñ≠)
    for k in 1:D
        # We make the following adaptation to Kressner2014:
        # Fix the i'th term of the sum and replace V·µ¢ by Q·µ¢ R·µ¢.
        # We can absorb the R factor into the core by replacing V·µ¢ by Q·µ¢
        # and C (in the i'th term of the sum) by C √ó·µ¢ R·µ¢
        Q, R = qr(V[k])
        idxOffset = CartesianIndex(ntuple(i -> i == k ? r‚Éó[k] : 0, D))
        ‚Ñ≠‚®â‚ÇñR = tensor_fold!(buffer, R * tensor_unfold!(buffer, ‚Ñ≠, k), k)
        S[CartesianIndices(‚Ñ≠) .+ idxOffset] = ‚Ñ≠‚®â‚ÇñR
        push!(UQ, hcat(U[k], Matrix(Q)))
    end

    #Convert to truncated HOSVD of p + x
    hosvd_S = st_hosvd(S, r‚Éó)
    factors = UQ .* hosvd_S.U
    for i in 1:D
        q.hosvd.U[i] .= factors[i]
        q.hosvd.œÉ[i] .= hosvd_S.œÉ[i]
    end
    q.hosvd.core .= hosvd_S.core
    return q
end

function Base.show(io::IO, ::MIME"text/plain", ùíØ::Tucker{N,R,D,ùîΩ}) where {N,R,D,ùîΩ}
    return print(io, "Tucker(", N, ", ", R, ", ", ùîΩ, ")")
end
function Base.show(io::IO, ::MIME"text/plain", ùîÑ::TuckerPoint)
    pre = " "
    summary(io, ùîÑ)
    for d in eachindex(ùîÑ.hosvd.U)
        println(io, string("\nU factor ", d, ":"))
        su = sprint(show, "text/plain", ùîÑ.hosvd.U[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCore:")
    su = sprint(show, "text/plain", ùîÑ.hosvd.core; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    return print(io, pre, su)
end
function Base.show(io::IO, ::MIME"text/plain", x::TuckerTVector)
    pre = " "
    summary(io, x)
    for d in eachindex(x.UÃá)
        println(io, string("\nUÃá factor ", d, ":"))
        su = sprint(show, "text/plain", x.UÃá[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCÃá factor:")
    su = sprint(show, "text/plain", x.CÃá; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    return print(io, pre, su)
end
function Base.show(io::IO, ::MIME"text/plain", ‚Ñ¨::CachedHOSVDBasis{ùîΩ,T,D}) where {ùîΩ,T,D}
    summary(io, ‚Ñ¨)
    print(io, " ‚âÖ")
    su = sprint(show, "text/plain", convert(Matrix{T}, ‚Ñ¨); context=io, sizehint=0)
    su = replace(su, '\n' => "\n ")
    return println(io, " ", su)
end

"""
    Base.size(p::TuckerPoint)

The dimensions of a [`TuckerPoint`](@ref) `p`, when regarded as a full tensor
(see [`embed`](@ref)).
"""
Base.size(ùîÑ::TuckerPoint) = map(u -> size(u, 1), ùîÑ.hosvd.U)

#=
Modification of the ST-HOSVD from [Vannieuwenhoven2012]
This is the HOSVD of an approximation of ùîÑ, i.e. the core of this decomposition
is also in HOSVD format.
=#
function st_hosvd(ùîÑ, mlrank=size(ùîÑ))
    T = eltype(ùîÑ)
    D = ndims(ùîÑ)
    n‚Éó = size(ùîÑ)
    # Add type assertions to U and œÉ for type stability
    U::NTuple{D,Matrix{T}} = ntuple(d -> Matrix{T}(undef, n‚Éó[d], mlrank[d]), D)
    œÉ::NTuple{D,Vector{T}} = ntuple(d -> Vector{T}(undef, mlrank[d]), D)
    # Initialise arrays to store successive truncations (ùîÑ‚Ä≤) and unfoldings (buffer)
    # so that the type remains constant at every truncation
    ùîÑ‚Ä≤ = reshape(view(ùîÑ, 1:length(ùîÑ)), n‚Éó)
    fold_buffer = reshape(view(similar(ùîÑ), 1:length(ùîÑ)), n‚Éó)
    unfold_buffer = view(similar(ùîÑ), 1:length(ùîÑ))

    for k in 1:D
        r‚Çñ = mlrank[k]
        ùîÑ‚Ä≤‚Çç‚Çñ‚Çé = tensor_unfold!(unfold_buffer, ùîÑ‚Ä≤, k)
        # truncated SVD + incremental construction of the core
        UŒ£V·µÄ = svd(ùîÑ‚Ä≤‚Çç‚Çñ‚Çé)
        U[k] .= UŒ£V·µÄ.U[:, 1:r‚Çñ]
        œÉ[k] .= UŒ£V·µÄ.S[1:r‚Çñ]
        ùîÑ‚Ä≤‚Çç‚Çñ‚Çé_trunc = Diagonal(œÉ[k]) * UŒ£V·µÄ.Vt[1:r‚Çñ, :]
        sizeùîÑ‚Ä≤ = ntuple(i -> i ‚â§ k ? mlrank[i] : n‚Éó[i], D)
        fold_buffer = reshape(view(fold_buffer, 1:prod(sizeùîÑ‚Ä≤)), sizeùîÑ‚Ä≤)
        unfold_buffer = view(unfold_buffer, 1:prod(sizeùîÑ‚Ä≤))
        ùîÑ‚Ä≤ = tensor_fold!(fold_buffer, ùîÑ‚Ä≤‚Çç‚Çñ‚Çé_trunc, k)
    end
    core = Array(ùîÑ‚Ä≤)

    # Make sure the truncated core is in "all-orthogonal" HOSVD format
    if mlrank ‚â† n‚Éó
        hosvd_core = st_hosvd(core, mlrank)
        U = U .* hosvd_core.U
        core = hosvd_core.core
        œÉ = hosvd_core.œÉ
    end

    return HOSVD{T,D}(U, core, œÉ)
end

# In-place inverse of the k'th unfolding of a size n‚ÇÅ √ó ... √ó n_D tensor.
# The size of the reshaped tensor is determined by the size of ùîÑ.
# The result is stored in ùîÑ. The returned value uses the same address space as ùîÑ.
function tensor_fold!(ùîÑ::AbstractArray{T,D}, ùîÑ‚Çç‚Çñ‚Çé::AbstractMatrix{T}, k) where {T,D}
    @assert length(ùîÑ‚Çç‚Çñ‚Çé) == length(ùîÑ) && size(ùîÑ‚Çç‚Çñ‚Çé, 1) == size(ùîÑ, k)
    @assert pointer(ùîÑ) !== pointer(ùîÑ‚Çç‚Çñ‚Çé)
    # Caution: tuple operations can be type unstable if used incorrectly
    œÉ(i) = i == 1 ? k : i ‚â§ k ? i - 1 : i
    œÉ‚Åª¬π(i) = i < k ? i + 1 : i == k ? 1 : i
    permuted_size = ntuple(i -> size(ùîÑ, œÉ(i)), D)
    return permutedims!(ùîÑ, reshape(ùîÑ‚Çç‚Çñ‚Çé, permuted_size), ntuple(œÉ‚Åª¬π, D))
end

# In-place mode-k unfolding of the array ùîÑ of order D ‚â• k.
# The argument buffer is an array of arbitrary dimensions of the same length as ùîÑ.
# The returned value uses the same address space as the buffer.
function tensor_unfold!(buffer, ùîÑ::AbstractArray{T,D}, k) where {T,D}
    @assert length(buffer) == length(ùîÑ)
    @assert pointer(ùîÑ) !== pointer(buffer)
    ùîÑ‚Çç‚Çñ‚Çé = reshape(buffer, size(ùîÑ, k), :)
    # Caution: tuple operations can be type unstable if used incorrectly
    œÉ(i) = i == 1 ? k : i ‚â§ k ? i - 1 : i
    permuted_size = ntuple(i -> size(ùîÑ, œÉ(i)), D)
    permutedims!(reshape(ùîÑ‚Çç‚Çñ‚Çé, permuted_size), ùîÑ, ntuple(œÉ, D))
    return ùîÑ‚Çç‚Çñ‚Çé
end

@doc raw"""
    zero_vector(::Tucker, p::TuckerPoint)

The zero element in the tangent space to `p` on the [`Tucker`](@ref) manifold, represented
as a [`TuckerTVector`](@ref).
"""
zero_vector(::Tucker, ::TuckerPoint)

function zero_vector!(::Tucker, X::TuckerTVector, ::TuckerPoint)
    for UÃá in X.UÃá
        fill!(UÃá, zero(eltype(UÃá)))
    end
    fill!(X.CÃá, zero(eltype(X.CÃá)))
    return X
end

# The standard implementation of allocate_result on vector-valued functions gives an element
# of the same type as the manifold point. We want a vector instead.
for fun in [:get_vector, :inverse_retract, :project, :zero_vector]
    @eval function ManifoldsBase.allocate_result(
        ::Tucker,
        ::typeof($(fun)),
        p::TuckerPoint,
        args...,
    )
        return TuckerTVector(allocate(p.hosvd.core), allocate(p.hosvd.U))
    end
end

function ManifoldsBase.allocate_result(::Tucker{N}, f::typeof(embed), p, args...) where {N}
    dims = N
    return Array{number_eltype(p),length(dims)}(undef, dims)
end
