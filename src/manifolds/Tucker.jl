
@doc raw"""
    Tucker{N, R, D, ğ”½} <: AbstractManifold{ğ”½}

The manifold of $N_1 \times \dots \times N_D$ real-valued or complex-valued tensors of
fixed multilinear rank $(R_1, \dots, R_D)$ . If $R_1 = \dots = R_D = 1$, this is the
manifold of rank-1 tensors.

# Representation in HOSVD format

Any tensor $\mathcal{A}$ on the Tucker manifold can be represented in HOSVD
[^DeLathauwer2000] form
```math
\mathcal{A} = (U_1,\dots,U_D) \cdot \mathcal{C}
```
where $\mathcal C \in \mathbb{F}^{R_1 \times \dots \times R_D}$ and, for $d=1,\dots,D$,
the matrix $U_d \in \mathbb{F}^{N_d \times R_d}$ contains the singular vectors of the
$d$th unfolding of $\mathcal{A}$

# Tangent space

The tangent space to the Tucker manifold at
$\mathcal{A} = (U_1,\dots,U_D) \cdot \mathcal{C}$ is [^Koch2010]
```math
T_{\mathcal{A}} \mathcal{M} =
\bigl\{
    (U_1,\dots,U_D) \cdot \dot{\mathcal{C}}
    + \sum_{d=1}^D \bigl(
        (U_1, \dots, U_{d-1}, \dot{U}_d, U_{d+1}, \dots, U_D)
        \cdot \mathcal{C}
    \bigr)
\bigr\}
```
where $\dot{\mathcal{C}}$ is arbitrary and $\dot{U}_d^{\mathrm{H}} U_d = 0$ for all $d$.

# Constructor
    Tucker(nâƒ— :: NTuple{D, Int}, râƒ— :: NTuple{D, Int}[, field = â„])

Generate the manifold of $N_1 \times \dots \times N_D$ tensors of fixed multilinear rank
$(R_1, \dots, R_D)$

[^DeLathauwer2000]:
    > Lieven De Lathauwer, Bart De Moor, Joos Vandewalle: "A multilinear singular value decomposition"
    > SIAM Journal on Matrix Analysis and Applications, 21(4), pp. 1253-1278, 2000
    > doi: [10.1137/S0895479896305696](https://doi.org/10.1137/S0895479896305696)

[^Koch2010]:
    > Othmar Koch, Christian Lubic, "Dynamical Tensor approximation"
    > SIAM Journal on Matrix Analysis and Applications, 31(5), pp. 2360-2375, 2010
    > doi: [10.1137/09076578X](https://doi.org/10.1137/09076578X)
"""
struct Tucker{N,R,D,ğ”½} <: AbstractManifold{ğ”½} end
function Tucker(nâƒ—::NTuple{D,Int}, râƒ—::NTuple{D,Int}, field::AbstractNumbers=â„) where {D}
    @assert isValidTuckerRank(nâƒ—, râƒ—)
    return Tucker{nâƒ—,râƒ—,D,field}()
end

#=
    HOSVD{T, D}

Higher-order singular value decomposition of an order D tensor with eltype T
fields:
* U: singular vectors of the unfoldings
* core: core tensor
* Ïƒ : singular values of the unfoldings
=#
struct HOSVD{T,D}
    U::NTuple{D,Matrix{T}}
    core::Array{T,D}
    Ïƒ::NTuple{D,Vector{T}}
end

"""
    TuckerPoint{T, D}

An order D tensor of fixed multilinear rank and entries of type T. The tensor is
represented in HOSVD form. See also [`Tucker`](@ref).

# Constructors:
    TuckerPoint(core :: AbstractArray{T, D}, factors :: Vararg{MtxT, D}) where {T, D, MtxT <: AbstractMatrix{T}}

A tensor of the form (factors[1], â€¦, factors[D]) â‹… core
where it is assumed that the dimensions of the core are the multilinear rank of the tensor.

    TuckerPoint(A :: AbstractArray{T, D}, mlrank :: NTuple{D, Int}) where {T, D}

The low-multilinear rank tensor arising from the sequentially truncated the higher-order
singular value decomposition of A [^Vannieuwenhoven2012].

[^Vannieuwenhoven2012]:
    > Nick Vannieuwenhoven, Raf Vandebril, Karl Meerbergen: "A new truncation strategy for the higher-order singular value decomposition"
    > SIAM Journal on Scientific Computing, 34(2), pp. 1027-1052, 2012
    > doi: [10.1137/110836067](https://doi.org/10.1137/110836067)

"""
struct TuckerPoint{T,D} <: AbstractManifoldPoint
    hosvd::HOSVD{T,D}
end
function TuckerPoint(
    core::AbstractArray{T,D}, factors::Vararg{MtxT,D}
) where {T,D,MtxT<:AbstractMatrix{T}}
    # Take the QR decompositions of the factors and multiply the R factors into the core
    qrfacs = qr.(factors)
    Q = map(qrfac -> qrfac.Q, qrfacs)
    R = map(qrfac -> qrfac.R, qrfacs)
    coreâ€² = reshape(Kronecker.:âŠ—(reverse(R)...) * vec(core), size(core))

    # Convert to HOSVD format by taking the HOSVD of the core
    decomp = st_hosvd(coreâ€²)
    factorsâ€² = Q .* decomp.U
    return TuckerPoint(HOSVD{T,D}(factorsâ€², decomp.core, decomp.Ïƒ))
end
function TuckerPoint(A::AbstractArray{T,D}, mlrank::NTuple{D,Int}) where {T,D}
    return TuckerPoint(st_hosvd(A, mlrank))
end

@doc raw"""
    TuckerTVector{T, D} <: TVector

Tangent space to the Tucker manifold at $x = (U_1,\dots,U_D) â‹… \mathcal{C}$. This vector is
represented as
```math
(U_1,\dots,U_D) \cdot \dot{\mathcal{C}} +
\sum_{d=1}^D (U_1,\dots,U_{d-1},\dot{U}_d,U_{d+1},\dots,U_D) \cdot \mathcal{C}
```
where $\dot{U}_d^\mathrm{H} U_d = 0$. See also [`Tucker`](@ref)
"""
struct TuckerTVector{T,D} <: TVector
    CÌ‡::Array{T,D}
    UÌ‡::NTuple{D,Matrix{T}}
end

# An implicitly stored basis of the tangent space to the Tucker manifold. This is the basis
# from [Dewaele2021] and acts as the default orthonormal basis.
struct HOSVDBasis{T,D}
    point::TuckerPoint{T,D}
    UâŠ¥::NTuple{D,Matrix{T}}
end
CachedHOSVDBasis{ğ”½,T,D} = CachedBasis{
    ğ”½,DefaultOrthonormalBasis{ğ”½,TangentSpaceType},HOSVDBasis{T,D}
}

âŠ—á´¿(a...) = Kronecker.:âŠ—(reverse(a)...)

Base.:*(s::Number, x::TuckerTVector) = TuckerTVector(s * x.CÌ‡, s .* x.UÌ‡)
Base.:*(x::TuckerTVector, s::Number) = TuckerTVector(x.CÌ‡ * s, x.UÌ‡ .* s)
Base.:/(x::TuckerTVector, s::Number) = TuckerTVector(x.CÌ‡ / s, x.UÌ‡ ./ s)
Base.:\(s::Number, x::TuckerTVector) = TuckerTVector(s \ x.CÌ‡, s .\ x.UÌ‡)
Base.:+(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÌ‡ + y.CÌ‡, x.UÌ‡ .+ y.UÌ‡)
Base.:-(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÌ‡ - y.CÌ‡, x.UÌ‡ .- y.UÌ‡)
Base.:-(x::TuckerTVector) = TuckerTVector(-x.CÌ‡, map(-, x.UÌ‡))
Base.:+(x::TuckerTVector) = TuckerTVector(x.CÌ‡, x.UÌ‡)
Base.:(==)(x::TuckerTVector, y::TuckerTVector) = (x.CÌ‡ == y.CÌ‡) && all(x.UÌ‡ .== y.UÌ‡)

allocate(p::TuckerPoint) = allocate(p, number_eltype(p))
function allocate(p::TuckerPoint, ::Type{T}) where {T}
    return TuckerPoint(
        HOSVD(allocate(p.hosvd.U, T), allocate(p.hosvd.core, T), allocate(p.hosvd.Ïƒ, T))
    )
end
allocate(x::TuckerTVector) = allocate(x, number_eltype(x))
function allocate(x::TuckerTVector, ::Type{T}) where {T}
    return TuckerTVector(allocate(x.CÌ‡, T), allocate(x.UÌ‡, T))
end

function allocate_vector(â„³::Tucker, ğ”„::TuckerPoint)
    return TuckerTVector(allocate(ğ”„.hosvd.core), allocate(ğ”„.hosvd.U))
end

@doc raw"""
    check_point(M::Tucker{N,R,D}, x; kwargs...) where {N,R,D}

Check whether the array or [`TuckerPoint`](@ref) x is a point on the [`Tucker`](@ref)
manifold, i.e. it is an $N_1 \times \dots \times N_D$ tensor of multilinear rank
$(R_1,\dots,R_D)$. The keyword arguments are passed to the matrix rank function applied to
the unfoldings.
For a [`TuckerPoint`](@ref) it is checked that the point is in correct HOSVD form.
"""
function check_point(M::Tucker{N,R,D}, x; kwargs...) where {N,R,D}
    s = "The point $(x) does not lie on $(M), "
    size(x) == N || return DomainError(size(x), s * "since its size is not $(N).")
    for d in 1:ndims(x)
        r = rank(unfold(x, d); kwargs...)
        r == R[d] || return DomainError(size(x), s * "since its rank is not $(R).")
    end
    return nothing
end
function check_point(M::Tucker{N,R,D}, x::TuckerPoint; kwargs...) where {N,R,D}
    s = "The point $(x) does not lie on $(M), "
    U = x.hosvd.U
    â„­ = x.hosvd.core
    ncolsU = map(u -> size(u, 2), U)
    if ncolsU â‰  size(â„­)
        return DomainError(
            ncolsU, s * "since the dimensions of the Tucker factors do not match"
        )
    end
    if size(â„­) â‰  R
        return DomainError(
            size(x.hosvd.core), s * "since the size of the core is not $(R)."
        )
    end
    if size(x) â‰  N
        return DomainError(size(x), s * "since its dimensions are not $(N).")
    end
    for u in U
        if u' * u â‰‰ LinearAlgebra.I
            return DomainError(
                norm(u' * u - LinearAlgebra.I),
                s * "since its factor matrices are not unitary.",
            )
        end
    end
    for d in 1:ndims(x.hosvd.core)
        gram = unfold(â„­, d) * unfold(â„­, d)'
        if gram â‰‰ Diagonal(x.hosvd.Ïƒ[d])^2
            return DomainError(
                norm(gram - Diagonal(x.hosvd.Ïƒ[d])^2),
                s *
                "since the unfoldings of the core are not diagonalised by" *
                "the singular values.",
            )
        end
        if rank(Diagonal(x.hosvd.Ïƒ[d]); kwargs...) â‰  R[d]
            return DomainError(
                minimum(x.hosvd.Ïƒ[d]),
                s * "since the core does not have full multilinear rank.",
            )
        end
    end
    return nothing
end

@doc raw"""
    check_vector(M::Tucker{N,R,D}, p::TuckerPoint{T,D}, v::TuckerTVector) where {N,R,T,D}

Check whether a [`TuckerTVector`](@ref) `v` is is in the tangent space to `M` at `p`. This
is the case when the dimensions of the factors in `v` agree with those of `p` and the factor
matrices of `v` are in the orthogonal complement of the HOSVD factors of `p`.
"""
function check_vector(
    M::Tucker{N,R,D}, p::TuckerPoint{T,D}, v::TuckerTVector
) where {N,R,T,D}
    s = "The tangent vector $(v) is not a tangent vector to $(p) on $(M), "
    if size(p.hosvd.core) â‰  size(v.CÌ‡) || any(size.(v.UÌ‡) .â‰  size.(p.hosvd.U))
        return DomainError(
            size(v.CÌ‡), s * "since the array dimensons of $(p) and $(v)" * "do not agree."
        )
    end
    for (U, UÌ‡) in zip(p.hosvd.U, v.UÌ‡)
        if norm(U' * UÌ‡) â‰¥ âˆšeps(eltype(U)) * âˆšlength(U)
            return DomainError(
                norm(U' * UÌ‡),
                s *
                "since the columns of x.hosvd.U are not" *
                "orthogonal to those of v.UÌ‡.",
            )
        end
    end
    return nothing
end

"""
    Base.convert(::Type{Matrix{T}}, basis :: CachedBasis{ğ”½,DefaultOrthonormalBasis{ğ”½, TangentSpaceType},HOSVDBasis{T, D}}) where {ğ”½, T, D}
    Base.convert(::Type{Matrix}, basis :: CachedBasis{ğ”½,DefaultOrthonormalBasis{ğ”½, TangentSpaceType},HOSVDBasis{T, D}}) where {ğ”½, T, D}

Convert a HOSVD basis to a matrix whose columns are the vectorisations of the basis vectors.
"""
function Base.convert(::Type{Matrix{T}}, â„¬::CachedHOSVDBasis{ğ”½,T,D}) where {ğ”½,T,D}
    ğ”„ = â„¬.data.point
    râƒ— = size(ğ”„.hosvd.core)
    nâƒ— = size(ğ”„)
    â„³ = Tucker(nâƒ—, râƒ—)

    J = Matrix{T}(undef, prod(nâƒ—), manifold_dimension(â„³))
    # compute all possible âˆ‚ğ”„â•±âˆ‚â„­ (in one go is quicker than one vector at a time)
    J[:, 1:prod(râƒ—)] = âŠ—á´¿(U...)
    # compute all possible âˆ‚ğ”„â•±âˆ‚U[d] for d = 1,...,D
    function fill_column!(i, váµ¢)
        Jáµ¢_tensor = reshape(view(J, :, i), nâƒ—) # changes to this apply to J as well
        return embed!(â„³, Jáµ¢_tensor, ğ”„, váµ¢)
    end
    foreach(fill_column!, â„³, ğ”„, â„¬, (prod(râƒ—) + 1):manifold_dimension(â„³))
    return J
end
function Base.convert(::Type{Matrix}, basis::CachedHOSVDBasis{ğ”½,T,D}) where {ğ”½,T,D}
    return convert(Matrix{T}, basis)
end

Base.copy(x::TuckerTVector) = TuckerTVector(copy(x.CÌ‡), map(copy, x.UÌ‡))

function Base.copyto!(q::TuckerPoint, p::TuckerPoint)
    for d in 1:ndims(q)
        copyto!(q.hosvd.U[d], p.hosvd.U[d])
        copyto!(q.hosvd.Ïƒ[d], p.hosvd.Ïƒ[d])
    end
    copyto!(q.hosvd.core, p.hosvd.core)
    return q
end
function Base.copyto!(y::TuckerTVector, x::TuckerTVector)
    for d in 1:ndims(y.CÌ‡)
        copyto!(y.UÌ‡[d], x.UÌ‡[d])
    end
    copyto!(y.CÌ‡, x.CÌ‡)
    return y
end

@doc raw"""
    embed(::Tucker, A :: TuckerPoint)

Convert a point `A` on the Tucker manifold to a full tensor, represented as an
$N_1 \times \dots \times N_D$-array.

    embed(::Tucker, A::TuckerPoint, X::TuckerTVector)

Convert a tangent vector `X` with base point `A` on the Tucker manifold to a full tensor,
epresented as an $N_1 \times \dots \times N_D$-array.
"""
function embed!(::Tucker, q, p::TuckerPoint)
    return copyto!(q, reshape(âŠ—á´¿(p.hosvd.U...) * vec(p.hosvd.core), size(p)))
end
function embed!(â„³::Tucker, Y, ğ”„::TuckerPoint{T,D}, X::TuckerTVector) where {T,D}
    Y .= reshape(âŠ—á´¿(ğ”„.hosvd.U...) * vec(X.CÌ‡), size(Y))
    Uâ„­ = embed(â„³, ğ”„)
    nâƒ— = size(Uâ„­)
    for d in 1:D
        Y .= Y + fold(X.UÌ‡[d] * (ğ”„.hosvd.U[d]' * unfold(Uâ„­, d)), d, nâƒ—)
    end
    return Y
end

# Inverse of the k'th unfolding of a size nâ‚ Ã— ... Ã— n_D tensor
function fold(ğ”„â™­::AbstractMatrix{T}, k, nâƒ—::NTuple{D,Int})::Array{T,D} where {T,D,Int}
    @assert 1 â‰¤ k â‰¤ D
    @assert size(ğ”„â™­, 1) == nâƒ—[k]

    # (compiler doesn't know we are reshaping back into order D array without type assertion)
    size_pre_permute::NTuple{D,Int} = (nâƒ—[k], nâƒ—[1:(k - 1)]..., nâƒ—[(k + 1):D]...)
    perm::NTuple{D,Int} = ((2:k)..., 1, ((k + 1):D)...)
    return permutedims(reshape(ğ”„â™­, size_pre_permute), perm)
end

@doc raw"""
    Base.foreach(f, M::Tucker, p::TuckerPoint, basis::AbstractBasis)

Let `basis` be and [`AbstractBasis`](@ref) at a point `p` on `M`. Suppose `f` is a function
that takes an index and a vector as an argument.
This function applies `f` to `i` and the `i`th basis vector sequentially for each `i` in
`indices`.
Using a [`CachedBasis`](@ref) may speed up the computation.

**NOTE**: The i'th basis vector is overwritten in each iteration. If any information about
the vector is to be stored, `f` must make a copy.
"""
function Base.foreach(
    f, M::Tucker, p::TuckerPoint, basis::AbstractBasis, indices=1:manifold_dimension(M)
)
    # Use mutating variants to avoid superfluous allocation
    báµ¢ = allocate_vector(M, p)
    eáµ¢ = zeros(number_eltype(p), manifold_dimension(M))
    for i in indices
        eáµ¢[i] = one(eltype(eáµ¢))
        get_vector!(M, báµ¢, p, eáµ¢, basis)
        eáµ¢[i] = zero(eltype(eáµ¢))
        f(i, báµ¢)
    end
end

@doc raw"""
    get_basis(:: Tucker, A :: TuckerPoint, basisType::DefaultOrthonormalBasis{ğ”½, TangentSpaceType}) where ğ”½

A implicitly stored basis of the tangent space to the Tucker manifold.
Assume $\mathcal{A} = (U_1,\dots,U_D) \cdot \mathcal{C}$ is in HOSVD format and that, for
$d=1,\dots,D$, the singular values of the
$d$'th unfolding are $\sigma_{dj}$, with $j = 1,\dots,R_d$.
The basis of the tangent space is as follows: [^Dewaele2021]

```math
\bigl\{
    (U_1,\dots,U_D) e_i
\bigr\} \cup \bigl\{
    (U_1,\dots, \sigma_{dj}^{-1} U_d^{\perp} e_i e_j^T,\dots,U_D) \cdot \mathcal{C}
\bigr\}
```

in which $U_d^\perp$ is such that $[U_d \quad U_d^{\perp}]$ forms an orthonormal basis
of $\mathbb{R}^{N_d}$, for each $d = 1,\dots,D$.

[^Dewaele2021]:
    > Nick Dewaele, Paul Breiding, Nick Vannieuwenhoven, "The condition number of many tensor decompositions is invariant under Tucker compression"
    > arxiv: #TODO
"""
function get_basis(
    ::Tucker,
    ğ”„::TuckerPoint,
    basisType::DefaultOrthonormalBasis{ğ”½,TangentSpaceType}=DefaultOrthonormalBasis(),
) where {ğ”½}
    D = ndims(ğ”„)
    nâƒ— = size(ğ”„)
    râƒ— = size(ğ”„.hosvd.core)

    U = ğ”„.hosvd.U
    UâŠ¥ = ntuple(d -> Matrix(qr(I - U[d] * U[d]', Val(true)).Q)[:, 1:(nâƒ—[d] - râƒ—[d])], D)

    basis = HOSVDBasis(ğ”„, UâŠ¥)
    return CachedBasis(basisType, basis)
end

"""
    get_coordinates(::Tucker, A, X :: TuckerTVector, b)

The coordinates of a tangent vector X at point A on the Tucker manifold with respect to the
basis b.
"""
function get_coordinates(::Tucker, ğ”„, X::TuckerTVector, â„¬::CachedHOSVDBasis)
    coords = vec(X.CÌ‡)
    for d in 1:length(X.UÌ‡)
        coord_mtx = (â„¬.data.UâŠ¥[d] \ X.UÌ‡[d]) * Diagonal(ğ”„.hosvd.Ïƒ[d])
        coords = vcat(coords, vec(coord_mtx'))
    end
    return coords
end
function get_coordinates(M::Tucker, ğ”„, X, â„¬::DefaultOrthonormalBasis)
    return get_coordinates(M, ğ”„, X, get_basis(M, ğ”„, â„¬))
end

"""
    get_vector(::Tucker, A, x, b)

The tangent vector at a point A whose coordinates with respect to the basis b are x.
"""
function get_vector!(
    ::Tucker, y, ğ”„::TuckerPoint, x::AbstractVector{T}, â„¬::CachedHOSVDBasis
) where {T}
    Î¾ = convert(Vector{promote_type(number_eltype(ğ”„), eltype(x))}, x)
    â„­ = ğ”„.hosvd.core
    Ïƒ = ğ”„.hosvd.Ïƒ
    UâŠ¥ = â„¬.data.UâŠ¥
    D = ndims(â„­)
    râƒ— = size(â„­)
    nâƒ— = size(ğ”„)

    # split Î¾ into Î¾_core and Î¾U so that vcat(Î¾_core, Î¾U...) == Î¾, but avoid copying
    Î¾_core = view(Î¾, 1:length(â„­))
    Î¾U = Vector{typeof(Î¾_core)}(undef, D)
    nextcolumn = length(â„­) + 1
    for d in 1:D
        numcols = râƒ—[d] * (nâƒ—[d] - râƒ—[d])
        Î¾U[d] = view(Î¾, nextcolumn:(nextcolumn + numcols - 1))
        nextcolumn += numcols
    end

    # Construct âˆ‚U[d] by plugging in the definition of the orthonormal basis [Dewaele2021]
    # âˆ‚U[d] = âˆ‘áµ¢â±¼ { Î¾U[d]áµ¢â±¼ (Ïƒ[d]â±¼)â»Â¹ UâŠ¥[d] ğáµ¢ ğâ±¼áµ€ }
    #       = UâŠ¥[d] * âˆ‘â±¼ (Ïƒ[d]â±¼)â»Â¹ (âˆ‘áµ¢ Î¾U[d]áµ¢â±¼  ğáµ¢) ğâ±¼áµ€
    # Î¾U[d] = [Î¾â‚â‚, ..., Î¾â‚â±¼, ..., Î¾áµ¢â‚, ..., Î¾áµ¢â±¼, ..., ]
    # => turn these i and j into matrix indices and do matrix operations
    for d in 1:D
        grid = transpose(reshape(Î¾U[d], râƒ—[d], nâƒ—[d] - râƒ—[d]))
        y.UÌ‡[d] .= UâŠ¥[d] * grid * Diagonal(1 ./ Ïƒ[d])
    end

    y.CÌ‡ .= reshape(Î¾_core, size(y.CÌ‡))
    return y
end
function get_vector!(â„³::Tucker, y, ğ”„::TuckerPoint, x, â„¬::DefaultOrthonormalBasis)
    return get_vector!(â„³, y, ğ”„, x, get_basis(â„³, ğ”„, â„¬))
end

function get_vectors(â„³::Tucker, ğ”„::TuckerPoint{T,D}, â„¬::CachedHOSVDBasis) where {T,D}
    vectors = Vector{TuckerTVector{T,D}}(undef, manifold_dimension(â„³))
    foreach((i, váµ¢) -> setindex!(vectors, copy(váµ¢), i), â„³, ğ”„, â„¬)
    return vectors
end
function get_vectors(â„³::Tucker, ğ”„::TuckerPoint, â„¬::DefaultOrthonormalBasis)
    return get_vectors(â„³, ğ”„, get_basis(â„³, ğ”„, â„¬))
end

"""
    inner(::Tucker, A::TuckerPoint, x::TuckerTVector, y::TuckerTVector)

The Euclidean inner product between tangent vectors `x` and `y` at the point `A` on
the Tucker manifold.function

    inner(::Tucker, A::TuckerPoint, x::TuckerTVector, y)
    inner(::Tucker, A::TuckerPoint, x, y::TuckerTVector)

The Euclidean inner product between `x` and `y` where `x` is a vector tangent to the Tucker
manifold at `A` and `y` is a vector or the ambient space or vice versa. The vector in the
ambient space is represented as a full tensor.
"""
function inner(::Tucker, ğ”„::TuckerPoint, x::TuckerTVector, y::TuckerTVector)
    â„­ = ğ”„.hosvd.core
    dotprod = dot(x.CÌ‡, y.CÌ‡)
    for d in 1:ndims(ğ”„)
        dotprod += dot(x.UÌ‡[d] * unfold(â„­, d), y.UÌ‡[d] * unfold(â„­, d))
    end
    return dotprod
end
inner(M::Tucker, ğ”„::TuckerPoint, x::TuckerTVector, y) = dot(embed(M, ğ”„, x), y)
inner(M::Tucker, ğ”„::TuckerPoint, x, y::TuckerTVector) = dot(x, embed(M, ğ”„, y))

"""
    inverse_retract(â„³::Tucker, A::TuckerPoint, B::TuckerPoint, r::ProjectionInverseRetraction)

The projection inverse retraction on the Tucker manifold interprets `B` as a point in the
ambient Euclidean space and projects it onto the tangent space at to `â„³` at `A`.
"""
function inverse_retract!(
    â„³::Tucker, X, ğ”„::TuckerPoint, ğ”…::TuckerPoint, ::ProjectionInverseRetraction
)
    diffVector = embed(â„³, ğ”…) - embed(â„³, ğ”„)
    return project!(â„³, X, ğ”„, diffVector)
end

function isapprox(p::TuckerPoint, q::TuckerPoint; kwargs...)
    â„³ = Tucker(size(p), size(p.hosvd.core))
    return isapprox(embed(â„³, p), embed(â„³, q); kwargs...)
end
isapprox(::Tucker, p::TuckerPoint, q::TuckerPoint; kwargs...) = isapprox(p, q; kwargs...)
function isapprox(M::Tucker, p::TuckerPoint, x::TuckerTVector, y::TuckerTVector; kwargs...)
    return isapprox(embed(M, p, x), embed(M, p, y); kwargs...)
end

"""
    isValidTuckerRank(nâƒ—, râƒ—)

Determines whether there are tensors of dimensions nâƒ— with multilinear rank râƒ—
"""
function isValidTuckerRank(nâƒ—, râƒ—)
    return all(râƒ— .â‰¤ nâƒ—) && all(ntuple(i -> râƒ—[i] â‰¤ prod(râƒ—) Ã· râƒ—[i], length(râƒ—)))
end

@doc raw"""
    manifold_dimension(::Tucker)

The dimension of the manifold of $N_1 \times \dots \times N_D$ tensors of multilinear
rank $R_1 \times \dots \times R_D$, i.e.
```math
    \mathrm{dim}(\mathcal{M}) = \prod_{d=1}^D R_d + \sum_{d=1}^D R_d (N_d - R_d).
```
"""
manifold_dimension(::Tucker{nâƒ—,râƒ—}) where {nâƒ—,râƒ—} = prod(râƒ—) + sum(râƒ— .* (nâƒ— .- râƒ—))

@doc raw"""
    Base.ndims(:: TuckerPoint{T, D})

The order of a tensor of low multilinear rank
"""
Base.ndims(::TuckerPoint{T,D}) where {T,D} = D

number_eltype(::TuckerPoint{T,D}) where {T,D} = T
number_eltype(::TuckerTVector{T,D}) where {T,D} = T

"""
    project(â„³::Tucker, ğ”„::TuckerPoint, X)

The least-squares projection of a tensor `X` to the tangent space to `â„³` at `A`.
"""
function project!(â„³::Tucker, Y, ğ”„::TuckerPoint, X)
    â„¬ = get_basis(â„³, ğ”„, DefaultOrthonormalBasis())
    coords = Vector{number_eltype(ğ”„)}(undef, manifold_dimension(â„³))
    f!(i, â„¬áµ¢) = setindex!(coords, inner(â„³, ğ”„, â„¬áµ¢, X), i)
    foreach(f!, â„³, ğ”„, â„¬)
    return get_vector!(â„³, Y, ğ”„, coords, â„¬)
end

representation_size(::Tucker{N}) where {N} = N

@doc raw"""
    retract(::Tucker, A, x, ::PolarRetraction)

The truncated HOSVD-based retraction [^Kressner2014] to the Tucker manifold, i.e.
$R_{\mathcal{A}}(x)$ is the sequentially tuncated HOSVD of $\mathcal{A} + x$

[^Kressner2014]:
    > Daniel Kressner, Michael Steinlechner, Bart Vandereycken: "Low-rank tensor completion by Riemannian optimization"
    > BIT Numerical Mathematics, 54(2), pp. 447-468, 2014
    > doi: [10.1007/s10543-013-0455-z](https://doi.org/10.1007/s10543-013-0455-z)

"""
retract(::Tucker, ::Any, ::Any, ::PolarRetraction)

function retract!(
    ::Tucker, q::TuckerPoint, p::TuckerPoint{T,D}, x::TuckerTVector, ::PolarRetraction
) where {T,D}
    U = p.hosvd.U
    V = x.UÌ‡
    â„­ = p.hosvd.core
    ğ”Š = x.CÌ‡
    râƒ— = size(â„­)

    # Build the core tensor S and the factors [Uáµˆ  Váµˆ]
    S = zeros(T, 2 .* size(â„­))
    S[CartesianIndices(â„­)] = â„­ + ğ”Š
    UQ = Matrix{T}[]
    for d in 1:D
        # We make the following adaptation to Kressner2014:
        # Fix the i'th term of the sum and replace Váµ¢ by Qáµ¢ Ráµ¢.
        # We can absorb the R factor into the core by replacing Váµ¢ by Qáµ¢
        # and C (in the i'th term of the sum) by C Ã—áµ¢ Ráµ¢
        Q, R = qr(V[d])
        idxOffset = CartesianIndex(ntuple(i -> i == d ? râƒ—[d] : 0, D))
        â„­_transf = fold(R * unfold(â„­, d), d, size(â„­))
        S[CartesianIndices(â„­) .+ idxOffset] = â„­_transf
        push!(UQ, hcat(U[d], Matrix(Q)))
    end

    #Convert to truncated HOSVD of p + x
    hosvd_S = st_hosvd(S, râƒ—)
    factors = UQ .* hosvd_S.U
    for i in 1:D
        q.hosvd.U[i] .= factors[i]
        q.hosvd.Ïƒ[i] .= hosvd_S.Ïƒ[i]
    end
    q.hosvd.core .= hosvd_S.core
    return q
end

function Base.show(io::IO, ::MIME"text/plain", ğ’¯::Tucker{N,R,D,ğ”½}) where {N,R,D,ğ”½}
    return print(io, "Tucker(", N, ", ", R, ", ", ğ”½, ")")
end
function Base.show(io::IO, ::MIME"text/plain", ğ”„::TuckerPoint)
    pre = " "
    summary(io, ğ”„)
    for d in eachindex(ğ”„.hosvd.U)
        println(io, string("\nU factor ", d, ":"))
        su = sprint(show, "text/plain", ğ”„.hosvd.U[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCore :")
    su = sprint(show, "text/plain", ğ”„.hosvd.core; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    return print(io, pre, su)
end
function Base.show(io::IO, ::MIME"text/plain", x::TuckerTVector)
    pre = " "
    summary(io, x)
    for d in eachindex(x.UÌ‡)
        println(io, string("\nUÌ‡ factor ", d, ":"))
        su = sprint(show, "text/plain", x.UÌ‡[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCÌ‡ factor :")
    su = sprint(show, "text/plain", x.CÌ‡; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    return print(io, pre, su)
end
function Base.show(io::IO, mime::MIME"text/plain", â„¬::CachedHOSVDBasis{ğ”½,T,D}) where {ğ”½,T,D}
    summary(io, â„¬)
    print(" â‰…")
    su = sprint(show, "text/plain", convert(Matrix{T}, â„¬); context=io, sizehint=0)
    su = replace(su, '\n' => "\n ")
    return println(io, " ", su)
end

"""
    Base.size(::TuckerPoint)

The dimensions of a tensor of low multilinear rank
"""
Base.size(ğ”„::TuckerPoint) = map(u -> size(u, 1), ğ”„.hosvd.U)

#=
Modification of the ST-HOSVD from [Vannieuwenhoven2012]
This is the HOSVD of an approximation of ğ”„, i.e. the core of this decomposition
is also in HOSVD format.
=#
function st_hosvd(ğ”„, mlrank=size(ğ”„))
    T = eltype(ğ”„)
    D = ndims(ğ”„)
    nâƒ— = size(ğ”„)
    # Add type assertions to U and Ïƒ for type stability
    U::NTuple{D,Matrix{T}} = ntuple(d -> Matrix{T}(undef, nâƒ—[d], mlrank[d]), D)
    Ïƒ::NTuple{D,Vector{T}} = ntuple(d -> Vector{T}(undef, mlrank[d]), D)

    for d in 1:D
        r_d = mlrank[d]
        ğ”„â½áµˆâ¾ = unfold(ğ”„, d)
        # truncated SVD + incremental construction of the core
        UÎ£Váµ€ = svd(ğ”„â½áµˆâ¾)
        U[d] .= UÎ£Váµ€.U[:, 1:r_d]
        Ïƒ[d] .= UÎ£Váµ€.S[1:r_d]
        ğ”„â½áµˆâ¾ = Diagonal(Ïƒ[d]) * UÎ£Váµ€.Vt[1:r_d, :]
        # Reshape; compiler doesn't know the order of the result without type assertion
        mâƒ—::NTuple{D,Int} = tuple(mlrank[1:d]..., nâƒ—[(d + 1):D]...)
        ğ”„ = fold(ğ”„â½áµˆâ¾, d, mâƒ—)
    end

    # Make sure the truncated core is in "all-orthogonal" HOSVD format
    if mlrank â‰  nâƒ—
        hosvd_core = st_hosvd(ğ”„, mlrank)
        U = U .* hosvd_core.U
        ğ”„ = hosvd_core.core
        Ïƒ = hosvd_core.Ïƒ
    end

    return HOSVD{T,D}(U, ğ”„, Ïƒ)
end

#Mode-k unfolding of the array ğ”„ of order D â‰¥ k
function unfold(ğ”„, k)
    d = ndims(ğ”„)
    ğ”„_ = permutedims(ğ”„, vcat(k, 1:(k - 1), (k + 1):d))
    return reshape(ğ”„_, size(ğ”„, k), div(length(ğ”„), size(ğ”„, k)))
end

@doc raw"""
    zero_vector(::Tucker, A::TuckerPoint)

The zero element in the tangent space to A on the Tucker manifold
"""
function zero_vector!(::Tucker, X::TuckerTVector, ::TuckerPoint)
    for UÌ‡ in X.UÌ‡
        fill!(UÌ‡, zero(eltype(UÌ‡)))
    end
    fill!(X.CÌ‡, zero(eltype(X.CÌ‡)))
    return X
end

# The standard implementation of allocate_result on vector-valued functions gives an element
# of the same type as the manifold point. We want a vector instead.
vector_result_fcns = [:get_vector, :inverse_retract, :project, :zero_vector]
for fun in vector_result_fcns
    @eval function ManifoldsBase.allocate_result(M::Tucker, f::typeof($(fun)), p, args...)
        return allocate_vector(M, p)
    end
end

function ManifoldsBase.allocate_result(M::Tucker, f::typeof(embed), p, args...)
    dims = representation_size(M)
    return Array{number_eltype(p),length(dims)}(undef, dims)
end
