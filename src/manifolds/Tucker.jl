
@doc raw"""
    Tucker{N, R, D, ùîΩ} <: AbstractManifold{ùîΩ}

The manifold of $N_1 \times \dots \times N_D$ real-valued or complex-valued tensors of
fixed multilinear rank $(R_1, \dots, R_D)$ . If $R_1 = \dots = R_D = 1$, this is the
manifold of rank-1 tensors.

# Representation in HOSVD format

Any tensor $\mathcal{A}$ on the Tucker manifold can be represented in HOSVD
[^DeLathauwer2000] form
```math
\mathcal{A} = (U_1,\dots,U_D) \cdot \mathcal{C}
```
where $\mathcal C \in \mathbb{F}^{R_1 \times \dots \times R_D}$ and, for $d=1,\dots,D$,
the matrix $U_d \in \mathbb{F}^{N_d \times R_d}$ contains the singular vectors of the
$d$th unfolding of $\mathcal{A}$

# Tangent space

The tangent space to the Tucker manifold at
$\mathcal{A} = (U_1,\dots,U_D) \cdot \mathcal{C}$ is [^Koch2010]
```math
T_{\mathcal{A}} \mathcal{M} =
\bigl\{
    (U_1,\dots,U_D) \cdot \dot{\mathcal{C}}
    + \sum_{d=1}^D \bigl(
        (U_1, \dots, U_{d-1}, \dot{U}_d, U_{d+1}, \dots, U_D)
        \cdot \mathcal{C}
    \bigr)
\bigr\}
```
where $\dot{\mathcal{C}}$ is arbitrary and $\dot{U}_d^{\mathrm{H}} U_d = 0$ for all $d$.

# Constructor
    Tucker(n‚Éó :: NTuple{D, Int}, r‚Éó :: NTuple{D, Int}[, field = ‚Ñù])

Generate the manifold of $N_1 \times \dots \times N_D$ tensors of fixed multilinear rank
$(R_1, \dots, R_D)$

[^DeLathauwer2000]:
    > Lieven De Lathauwer, Bart De Moor, Joos Vandewalle: "A multilinear singular value decomposition"
    > SIAM Journal on Matrix Analysis and Applications, 21(4), pp. 1253-1278, 2000
    > doi: [10.1137/S0895479896305696](https://doi.org/10.1137/S0895479896305696)

[^Koch2010]:
    > Othmar Koch, Christian Lubic, "Dynamical Tensor approximation"
    > SIAM Journal on Matrix Analysis and Applications, 31(5), pp. 2360-2375, 2010
    > doi: [10.1137/09076578X](https://doi.org/10.1137/09076578X)
"""
struct Tucker{N,R,D,ùîΩ} <: AbstractManifold{ùîΩ} end
function Tucker(n‚Éó::NTuple{D,Int}, r‚Éó::NTuple{D,Int}, field::AbstractNumbers=‚Ñù) where {D}
    @assert isValidTuckerRank(n‚Éó, r‚Éó)
    return Tucker{n‚Éó,r‚Éó,D,field}()
end

#=
    HOSVD{T, D}

Higher-order singular value decomposition of an order D tensor with eltype T
fields:
* U: singular vectors of the unfoldings
* core: core tensor
* œÉ : singular values of the unfoldings
=#
struct HOSVD{T,D}
    U::NTuple{D,Matrix{T}}
    core::Array{T,D}
    œÉ::NTuple{D,Vector{T}}
end

"""
    TuckerPoint{T, D}

An order D tensor of fixed multilinear rank and entries of type T. The tensor is
represented in HOSVD form. See also [`Tucker`](@ref).

# Constructors:
    TuckerPoint(core :: AbstractArray{T, D}, factors :: Vararg{MtxT, D}) where {T, D, MtxT <: AbstractMatrix{T}}

A tensor of the form (factors[1], ‚Ä¶, factors[D]) ‚ãÖ core
where it is assumed that the dimensions of the core are the multilinear rank of the tensor.

    TuckerPoint(A :: AbstractArray{T, D}, mlrank :: NTuple{D, Int}) where {T, D}

The low-multilinear rank tensor arising from the sequentially truncated the higher-order
singular value decomposition of A [^Vannieuwenhoven2012].

[^Vannieuwenhoven2012]:
    > Nick Vannieuwenhoven, Raf Vandebril, Karl Meerbergen: "A new truncation strategy for the higher-order singular value decomposition"
    > SIAM Journal on Scientific Computing, 34(2), pp. 1027-1052, 2012
    > doi: [10.1137/110836067](https://doi.org/10.1137/110836067)

"""
struct TuckerPoint{T,D} <: AbstractManifoldPoint
    hosvd::HOSVD{T,D}
end
function TuckerPoint(
    core::AbstractArray{T,D}, factors::Vararg{MtxT,D}
) where {T,D,MtxT<:AbstractMatrix{T}}
    # Take the QR decompositions of the factors and multiply the R factors into the core
    qrfacs = qr.(factors)
    Q = map(qrfac -> qrfac.Q, qrfacs)
    R = map(qrfac -> qrfac.R, qrfacs)
    core‚Ä≤ = reshape(Kronecker.:‚äó(reverse(R)...) * vec(core), size(core))

    # Convert to HOSVD format by taking the HOSVD of the core
    decomp = st_hosvd(core‚Ä≤)
    factors‚Ä≤ = Q .* decomp.U
    return TuckerPoint(HOSVD{T,D}(factors‚Ä≤, decomp.core, decomp.œÉ))
end
function TuckerPoint(A::AbstractArray{T,D}, mlrank::NTuple{D,Int}) where {T,D}
    return TuckerPoint(st_hosvd(A, mlrank))
end

@doc raw"""
    TuckerTVector{T, D} <: TVector

Tangent space to the Tucker manifold at $x = (U_1,\dots,U_D) ‚ãÖ \mathcal{C}$. This vector is
represented as
```math
(U_1,\dots,U_D) \cdot \dot{\mathcal{C}} +
\sum_{d=1}^D (U_1,\dots,U_{d-1},\dot{U}_d,U_{d+1},\dots,U_D) \cdot \mathcal{C}
```
where $\dot{U}_d^\mathrm{H} U_d = 0$. See also [`Tucker`](@ref)
"""
struct TuckerTVector{T,D} <: TVector
    CÃá::Array{T,D}
    UÃá::NTuple{D,Matrix{T}}
end

# An implicitly stored basis of the tangent space to the Tucker manifold. This is the basis
# from [Dewaele2021] and acts as the default orthonormal basis.
struct HOSVDBasis{T,D}
    point::TuckerPoint{T,D}
    U‚ä•::NTuple{D,Matrix{T}}
end
CachedHOSVDBasis{ùîΩ,T,D} = CachedBasis{
    ùîΩ,DefaultOrthonormalBasis{ùîΩ,TangentSpaceType},HOSVDBasis{T,D}
}

‚äó·¥ø(a...) = Kronecker.:‚äó(reverse(a)...)

Base.:*(s::Number, x::TuckerTVector) = TuckerTVector(s * x.CÃá, s .* x.UÃá)
Base.:*(x::TuckerTVector, s::Number) = TuckerTVector(x.CÃá * s, x.UÃá .* s)
Base.:/(x::TuckerTVector, s::Number) = TuckerTVector(x.CÃá / s, x.UÃá ./ s)
Base.:\(s::Number, x::TuckerTVector) = TuckerTVector(s \ x.CÃá, s .\ x.UÃá)
Base.:+(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÃá + y.CÃá, x.UÃá .+ y.UÃá)
Base.:-(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÃá - y.CÃá, x.UÃá .- y.UÃá)
Base.:-(x::TuckerTVector) = TuckerTVector(-x.CÃá, map(-, x.UÃá))
Base.:+(x::TuckerTVector) = TuckerTVector(x.CÃá, x.UÃá)
Base.:(==)(x::TuckerTVector, y::TuckerTVector) = (x.CÃá == y.CÃá) && all(x.UÃá .== y.UÃá)

allocate(p::TuckerPoint) = allocate(p, number_eltype(p))
function allocate(p::TuckerPoint, ::Type{T}) where {T}
    return TuckerPoint(
        HOSVD(allocate(p.hosvd.U, T), allocate(p.hosvd.core, T), allocate(p.hosvd.œÉ, T))
    )
end
allocate(x::TuckerTVector) = allocate(x, number_eltype(x))
function allocate(x::TuckerTVector, ::Type{T}) where {T}
    return TuckerTVector(allocate(x.CÃá, T), allocate(x.UÃá, T))
end

function allocate_vector(‚Ñ≥::Tucker, ùîÑ::TuckerPoint)
    return TuckerTVector(allocate(ùîÑ.hosvd.core), allocate(ùîÑ.hosvd.U))
end

@doc raw"""
    check_point(M::Tucker{N,R,D}, x; kwargs...) where {N,R,D}

Check whether the array or [`TuckerPoint`](@ref) x is a point on the [`Tucker`](@ref)
manifold, i.e. it is an $N_1 \times \dots \times N_D$ tensor of multilinear rank
$(R_1,\dots,R_D)$. The keyword arguments are passed to the matrix rank function applied to
the unfoldings.
For a [`TuckerPoint`](@ref) it is checked that the point is in correct HOSVD form.
"""
function check_point(M::Tucker{N,R,D}, x; kwargs...) where {N,R,D}
    s = "The point $(x) does not lie on $(M), "
    size(x) == N || return DomainError(size(x), s * "since its size is not $(N).")
    for d in 1:ndims(x)
        r = rank(unfold(x, d); kwargs...)
        r == R[d] || return DomainError(size(x), s * "since its rank is not $(R).")
    end
    return nothing
end
function check_point(M::Tucker{N,R,D}, x::TuckerPoint; kwargs...) where {N,R,D}
    s = "The point $(x) does not lie on $(M), "
    U = x.hosvd.U
    ‚Ñ≠ = x.hosvd.core
    ncolsU = map(u -> size(u, 2), U)
    if ncolsU ‚â† size(‚Ñ≠)
        return DomainError(
            ncolsU, s * "since the dimensions of the Tucker factors do not match"
        )
    end
    if size(‚Ñ≠) ‚â† R
        return DomainError(
            size(x.hosvd.core), s * "since the size of the core is not $(R)."
        )
    end
    if size(x) ‚â† N
        return DomainError(size(x), s * "since its dimensions are not $(N).")
    end
    for u in U
        if u' * u ‚ââ LinearAlgebra.I
            return DomainError(
                norm(u' * u - LinearAlgebra.I),
                s * "since its factor matrices are not unitary.",
            )
        end
    end
    for d in 1:ndims(x.hosvd.core)
        gram = unfold(‚Ñ≠, d) * unfold(‚Ñ≠, d)'
        if gram ‚ââ Diagonal(x.hosvd.œÉ[d])^2
            return DomainError(
                norm(gram - Diagonal(x.hosvd.œÉ[d])^2),
                s *
                "since the unfoldings of the core are not diagonalised by" *
                "the singular values.",
            )
        end
        if rank(Diagonal(x.hosvd.œÉ[d]); kwargs...) ‚â† R[d]
            return DomainError(
                minimum(x.hosvd.œÉ[d]),
                s * "since the core does not have full multilinear rank.",
            )
        end
    end
    return nothing
end

@doc raw"""
    check_vector(M::Tucker{N,R,D}, p::TuckerPoint{T,D}, v::TuckerTVector) where {N,R,T,D}

Check whether a [`TuckerTVector`](@ref) `v` is is in the tangent space to `M` at `p`. This
is the case when the dimensions of the factors in `v` agree with those of `p` and the factor
matrices of `v` are in the orthogonal complement of the HOSVD factors of `p`.
"""
function check_vector(
    M::Tucker{N,R,D}, p::TuckerPoint{T,D}, v::TuckerTVector
) where {N,R,T,D}
    s = "The tangent vector $(v) is not a tangent vector to $(p) on $(M), "
    if size(p.hosvd.core) ‚â† size(v.CÃá) || any(size.(v.UÃá) .‚â† size.(p.hosvd.U))
        return DomainError(
            size(v.CÃá), s * "since the array dimensons of $(p) and $(v)" * "do not agree."
        )
    end
    for (U, UÃá) in zip(p.hosvd.U, v.UÃá)
        if norm(U' * UÃá) ‚â• ‚àöeps(eltype(U)) * ‚àölength(U)
            return DomainError(
                norm(U' * UÃá),
                s *
                "since the columns of x.hosvd.U are not" *
                "orthogonal to those of v.UÃá.",
            )
        end
    end
    return nothing
end

"""
    Base.convert(::Type{Matrix{T}}, basis :: CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ, TangentSpaceType},HOSVDBasis{T, D}}) where {ùîΩ, T, D}
    Base.convert(::Type{Matrix}, basis :: CachedBasis{ùîΩ,DefaultOrthonormalBasis{ùîΩ, TangentSpaceType},HOSVDBasis{T, D}}) where {ùîΩ, T, D}

Convert a HOSVD basis to a matrix whose columns are the vectorisations of the basis vectors.
"""
function Base.convert(::Type{Matrix{T}}, ‚Ñ¨::CachedHOSVDBasis{ùîΩ,T,D}) where {ùîΩ,T,D}
    ùîÑ = ‚Ñ¨.data.point
    r‚Éó = size(ùîÑ.hosvd.core)
    n‚Éó = size(ùîÑ)
    ‚Ñ≥ = Tucker(n‚Éó, r‚Éó)

    J = Matrix{T}(undef, prod(n‚Éó), manifold_dimension(‚Ñ≥))
    # compute all possible ‚àÇùîÑ‚ï±‚àÇ‚Ñ≠ (in one go is quicker than one vector at a time)
    J[:, 1:prod(r‚Éó)] = ‚äó·¥ø(U...)
    # compute all possible ‚àÇùîÑ‚ï±‚àÇU[d] for d = 1,...,D
    function fill_column!(i, v·µ¢)
        J·µ¢_tensor = reshape(view(J, :, i), n‚Éó) # changes to this apply to J as well
        return embed!(‚Ñ≥, J·µ¢_tensor, ùîÑ, v·µ¢)
    end
    foreach(fill_column!, ‚Ñ≥, ùîÑ, ‚Ñ¨, (prod(r‚Éó) + 1):manifold_dimension(‚Ñ≥))
    return J
end
function Base.convert(::Type{Matrix}, basis::CachedHOSVDBasis{ùîΩ,T,D}) where {ùîΩ,T,D}
    return convert(Matrix{T}, basis)
end

Base.copy(x::TuckerTVector) = TuckerTVector(copy(x.CÃá), map(copy, x.UÃá))

function Base.copyto!(q::TuckerPoint, p::TuckerPoint)
    for d in 1:ndims(q)
        copyto!(q.hosvd.U[d], p.hosvd.U[d])
        copyto!(q.hosvd.œÉ[d], p.hosvd.œÉ[d])
    end
    copyto!(q.hosvd.core, p.hosvd.core)
    return q
end
function Base.copyto!(y::TuckerTVector, x::TuckerTVector)
    for d in 1:ndims(y.CÃá)
        copyto!(y.UÃá[d], x.UÃá[d])
    end
    copyto!(y.CÃá, x.CÃá)
    return y
end

@doc raw"""
    embed(::Tucker, A :: TuckerPoint)

Convert a point `A` on the Tucker manifold to a full tensor, represented as an
$N_1 \times \dots \times N_D$-array.

    embed(::Tucker, A::TuckerPoint, X::TuckerTVector)

Convert a tangent vector `X` with base point `A` on the Tucker manifold to a full tensor,
epresented as an $N_1 \times \dots \times N_D$-array.
"""
function embed!(::Tucker, q, p::TuckerPoint)
    return copyto!(q, reshape(‚äó·¥ø(p.hosvd.U...) * vec(p.hosvd.core), size(p)))
end
function embed!(‚Ñ≥::Tucker, Y, ùîÑ::TuckerPoint{T,D}, X::TuckerTVector) where {T,D}
    Y .= reshape(‚äó·¥ø(ùîÑ.hosvd.U...) * vec(X.CÃá), size(Y))
    U‚Ñ≠ = embed(‚Ñ≥, ùîÑ)
    n‚Éó = size(U‚Ñ≠)
    for d in 1:D
        Y .= Y + fold(X.UÃá[d] * (ùîÑ.hosvd.U[d]' * unfold(U‚Ñ≠, d)), d, n‚Éó)
    end
    return Y
end

# Inverse of the k'th unfolding of a size n‚ÇÅ √ó ... √ó n_D tensor
function fold(ùîÑ‚ô≠::AbstractMatrix{T}, k, n‚Éó::NTuple{D,Int})::Array{T,D} where {T,D,Int}
    @assert 1 ‚â§ k ‚â§ D
    @assert size(ùîÑ‚ô≠, 1) == n‚Éó[k]

    # (compiler doesn't know we are reshaping back into order D array without type assertion)
    size_pre_permute::NTuple{D,Int} = (n‚Éó[k], n‚Éó[1:(k - 1)]..., n‚Éó[(k + 1):D]...)
    perm::NTuple{D,Int} = ((2:k)..., 1, ((k + 1):D)...)
    return permutedims(reshape(ùîÑ‚ô≠, size_pre_permute), perm)
end

@doc raw"""
    Base.foreach(f, M::Tucker, p::TuckerPoint, basis::AbstractBasis)

Let `basis` be and [`AbstractBasis`](@ref) at a point `p` on `M`. Suppose `f` is a function
that takes an index and a vector as an argument.
This function applies `f` to `i` and the `i`th basis vector sequentially for each `i` in
`indices`.
Using a [`CachedBasis`](@ref) may speed up the computation.

**NOTE**: The i'th basis vector is overwritten in each iteration. If any information about
the vector is to be stored, `f` must make a copy.
"""
function Base.foreach(
    f, M::Tucker, p::TuckerPoint, basis::AbstractBasis, indices=1:manifold_dimension(M)
)
    # Use mutating variants to avoid superfluous allocation
    b·µ¢ = allocate_vector(M, p)
    e·µ¢ = zeros(number_eltype(p), manifold_dimension(M))
    for i in indices
        e·µ¢[i] = one(eltype(e·µ¢))
        get_vector!(M, b·µ¢, p, e·µ¢, basis)
        e·µ¢[i] = zero(eltype(e·µ¢))
        f(i, b·µ¢)
    end
end

@doc raw"""
    get_basis(:: Tucker, A :: TuckerPoint, basisType::DefaultOrthonormalBasis{ùîΩ, TangentSpaceType}) where ùîΩ

A implicitly stored basis of the tangent space to the Tucker manifold.
Assume $\mathcal{A} = (U_1,\dots,U_D) \cdot \mathcal{C}$ is in HOSVD format and that, for
$d=1,\dots,D$, the singular values of the
$d$'th unfolding are $\sigma_{dj}$, with $j = 1,\dots,R_d$.
The basis of the tangent space is as follows: [^Dewaele2021]

```math
\bigl\{
    (U_1,\dots,U_D) e_i
\bigr\} \cup \bigl\{
    (U_1,\dots, \sigma_{dj}^{-1} U_d^{\perp} e_i e_j^T,\dots,U_D) \cdot \mathcal{C}
\bigr\}
```

in which $U_d^\perp$ is such that $[U_d \quad U_d^{\perp}]$ forms an orthonormal basis
of $\mathbb{R}^{N_d}$, for each $d = 1,\dots,D$.

[^Dewaele2021]:
    > Nick Dewaele, Paul Breiding, Nick Vannieuwenhoven, "The condition number of many tensor decompositions is invariant under Tucker compression"
    > arxiv: #TODO
"""
function get_basis(
    ::Tucker,
    ùîÑ::TuckerPoint,
    basisType::DefaultOrthonormalBasis{ùîΩ,TangentSpaceType}=DefaultOrthonormalBasis(),
) where {ùîΩ}
    D = ndims(ùîÑ)
    n‚Éó = size(ùîÑ)
    r‚Éó = size(ùîÑ.hosvd.core)

    U = ùîÑ.hosvd.U
    U‚ä• = ntuple(d -> Matrix(qr(I - U[d] * U[d]', Val(true)).Q)[:, 1:(n‚Éó[d] - r‚Éó[d])], D)

    basis = HOSVDBasis(ùîÑ, U‚ä•)
    return CachedBasis(basisType, basis)
end

"""
    get_coordinates(::Tucker, A, X :: TuckerTVector, b)

The coordinates of a tangent vector X at point A on the Tucker manifold with respect to the
basis b.
"""
function get_coordinates(::Tucker, ùîÑ, X::TuckerTVector, ‚Ñ¨::CachedHOSVDBasis)
    coords = vec(X.CÃá)
    for d in 1:length(X.UÃá)
        coord_mtx = (‚Ñ¨.data.U‚ä•[d] \ X.UÃá[d]) * Diagonal(ùîÑ.hosvd.œÉ[d])
        coords = vcat(coords, vec(coord_mtx'))
    end
    return coords
end
function get_coordinates(M::Tucker, ùîÑ, X, ‚Ñ¨::DefaultOrthonormalBasis)
    return get_coordinates(M, ùîÑ, X, get_basis(M, ùîÑ, ‚Ñ¨))
end

"""
    get_vector(::Tucker, A, x, b)

The tangent vector at a point A whose coordinates with respect to the basis b are x.
"""
function get_vector!(
    ::Tucker, y, ùîÑ::TuckerPoint, x::AbstractVector{T}, ‚Ñ¨::CachedHOSVDBasis
) where {T}
    Œæ = convert(Vector{promote_type(number_eltype(ùîÑ), eltype(x))}, x)
    ‚Ñ≠ = ùîÑ.hosvd.core
    œÉ = ùîÑ.hosvd.œÉ
    U‚ä• = ‚Ñ¨.data.U‚ä•
    D = ndims(‚Ñ≠)
    r‚Éó = size(‚Ñ≠)
    n‚Éó = size(ùîÑ)

    # split Œæ into Œæ_core and ŒæU so that vcat(Œæ_core, ŒæU...) == Œæ, but avoid copying
    Œæ_core = view(Œæ, 1:length(‚Ñ≠))
    ŒæU = Vector{typeof(Œæ_core)}(undef, D)
    nextcolumn = length(‚Ñ≠) + 1
    for d in 1:D
        numcols = r‚Éó[d] * (n‚Éó[d] - r‚Éó[d])
        ŒæU[d] = view(Œæ, nextcolumn:(nextcolumn + numcols - 1))
        nextcolumn += numcols
    end

    # Construct ‚àÇU[d] by plugging in the definition of the orthonormal basis [Dewaele2021]
    # ‚àÇU[d] = ‚àë·µ¢‚±º { ŒæU[d]·µ¢‚±º (œÉ[d]‚±º)‚Åª¬π U‚ä•[d] ùêû·µ¢ ùêû‚±º·µÄ }
    #       = U‚ä•[d] * ‚àë‚±º (œÉ[d]‚±º)‚Åª¬π (‚àë·µ¢ ŒæU[d]·µ¢‚±º  ùêû·µ¢) ùêû‚±º·µÄ
    # ŒæU[d] = [Œæ‚ÇÅ‚ÇÅ, ..., Œæ‚ÇÅ‚±º, ..., Œæ·µ¢‚ÇÅ, ..., Œæ·µ¢‚±º, ..., ]
    # => turn these i and j into matrix indices and do matrix operations
    for d in 1:D
        grid = transpose(reshape(ŒæU[d], r‚Éó[d], n‚Éó[d] - r‚Éó[d]))
        y.UÃá[d] .= U‚ä•[d] * grid * Diagonal(1 ./ œÉ[d])
    end

    y.CÃá .= reshape(Œæ_core, size(y.CÃá))
    return y
end
function get_vector!(‚Ñ≥::Tucker, y, ùîÑ::TuckerPoint, x, ‚Ñ¨::DefaultOrthonormalBasis)
    return get_vector!(‚Ñ≥, y, ùîÑ, x, get_basis(‚Ñ≥, ùîÑ, ‚Ñ¨))
end

function get_vectors(‚Ñ≥::Tucker, ùîÑ::TuckerPoint{T,D}, ‚Ñ¨::CachedHOSVDBasis) where {T,D}
    vectors = Vector{TuckerTVector{T,D}}(undef, manifold_dimension(‚Ñ≥))
    foreach((i, v·µ¢) -> setindex!(vectors, copy(v·µ¢), i), ‚Ñ≥, ùîÑ, ‚Ñ¨)
    return vectors
end
function get_vectors(‚Ñ≥::Tucker, ùîÑ::TuckerPoint, ‚Ñ¨::DefaultOrthonormalBasis)
    return get_vectors(‚Ñ≥, ùîÑ, get_basis(‚Ñ≥, ùîÑ, ‚Ñ¨))
end

"""
    inner(::Tucker, A::TuckerPoint, x::TuckerTVector, y::TuckerTVector)

The Euclidean inner product between tangent vectors `x` and `y` at the point `A` on
the Tucker manifold.function

    inner(::Tucker, A::TuckerPoint, x::TuckerTVector, y)
    inner(::Tucker, A::TuckerPoint, x, y::TuckerTVector)

The Euclidean inner product between `x` and `y` where `x` is a vector tangent to the Tucker
manifold at `A` and `y` is a vector or the ambient space or vice versa. The vector in the
ambient space is represented as a full tensor.
"""
function inner(::Tucker, ùîÑ::TuckerPoint, x::TuckerTVector, y::TuckerTVector)
    ‚Ñ≠ = ùîÑ.hosvd.core
    dotprod = dot(x.CÃá, y.CÃá)
    for d in 1:ndims(ùîÑ)
        dotprod += dot(x.UÃá[d] * unfold(‚Ñ≠, d), y.UÃá[d] * unfold(‚Ñ≠, d))
    end
    return dotprod
end
inner(M::Tucker, ùîÑ::TuckerPoint, x::TuckerTVector, y) = dot(embed(M, ùîÑ, x), y)
inner(M::Tucker, ùîÑ::TuckerPoint, x, y::TuckerTVector) = dot(x, embed(M, ùîÑ, y))

"""
    inverse_retract(‚Ñ≥::Tucker, A::TuckerPoint, B::TuckerPoint, r::ProjectionInverseRetraction)

The projection inverse retraction on the Tucker manifold interprets `B` as a point in the
ambient Euclidean space and projects it onto the tangent space at to `‚Ñ≥` at `A`.
"""
function inverse_retract!(
    ‚Ñ≥::Tucker, X, ùîÑ::TuckerPoint, ùîÖ::TuckerPoint, ::ProjectionInverseRetraction
)
    diffVector = embed(‚Ñ≥, ùîÖ) - embed(‚Ñ≥, ùîÑ)
    return project!(‚Ñ≥, X, ùîÑ, diffVector)
end

function isapprox(p::TuckerPoint, q::TuckerPoint; kwargs...)
    ‚Ñ≥ = Tucker(size(p), size(p.hosvd.core))
    return isapprox(embed(‚Ñ≥, p), embed(‚Ñ≥, q); kwargs...)
end
isapprox(::Tucker, p::TuckerPoint, q::TuckerPoint; kwargs...) = isapprox(p, q; kwargs...)
function isapprox(M::Tucker, p::TuckerPoint, x::TuckerTVector, y::TuckerTVector; kwargs...)
    return isapprox(embed(M, p, x), embed(M, p, y); kwargs...)
end

"""
    isValidTuckerRank(n‚Éó, r‚Éó)

Determines whether there are tensors of dimensions n‚Éó with multilinear rank r‚Éó
"""
function isValidTuckerRank(n‚Éó, r‚Éó)
    return all(r‚Éó .‚â§ n‚Éó) && all(ntuple(i -> r‚Éó[i] ‚â§ prod(r‚Éó) √∑ r‚Éó[i], length(r‚Éó)))
end

@doc raw"""
    manifold_dimension(::Tucker)

The dimension of the manifold of $N_1 \times \dots \times N_D$ tensors of multilinear
rank $R_1 \times \dots \times R_D$, i.e.
```math
    \mathrm{dim}(\mathcal{M}) = \prod_{d=1}^D R_d + \sum_{d=1}^D R_d (N_d - R_d).
```
"""
manifold_dimension(::Tucker{n‚Éó,r‚Éó}) where {n‚Éó,r‚Éó} = prod(r‚Éó) + sum(r‚Éó .* (n‚Éó .- r‚Éó))

@doc raw"""
    Base.ndims(:: TuckerPoint{T, D})

The order of a tensor of low multilinear rank
"""
Base.ndims(::TuckerPoint{T,D}) where {T,D} = D

number_eltype(::TuckerPoint{T,D}) where {T,D} = T
number_eltype(::TuckerTVector{T,D}) where {T,D} = T

"""
    project(‚Ñ≥::Tucker, ùîÑ::TuckerPoint, X)

The least-squares projection of a tensor `X` to the tangent space to `‚Ñ≥` at `A`.
"""
function project!(‚Ñ≥::Tucker, Y, ùîÑ::TuckerPoint, X)
    ‚Ñ¨ = get_basis(‚Ñ≥, ùîÑ, DefaultOrthonormalBasis())
    coords = Vector{number_eltype(ùîÑ)}(undef, manifold_dimension(‚Ñ≥))
    f!(i, ‚Ñ¨·µ¢) = setindex!(coords, inner(‚Ñ≥, ùîÑ, ‚Ñ¨·µ¢, X), i)
    foreach(f!, ‚Ñ≥, ùîÑ, ‚Ñ¨)
    return get_vector!(‚Ñ≥, Y, ùîÑ, coords, ‚Ñ¨)
end

representation_size(::Tucker{N}) where {N} = N

@doc raw"""
    retract(::Tucker, A, x, ::PolarRetraction)

The truncated HOSVD-based retraction [^Kressner2014] to the Tucker manifold, i.e.
$R_{\mathcal{A}}(x)$ is the sequentially tuncated HOSVD of $\mathcal{A} + x$

[^Kressner2014]:
    > Daniel Kressner, Michael Steinlechner, Bart Vandereycken: "Low-rank tensor completion by Riemannian optimization"
    > BIT Numerical Mathematics, 54(2), pp. 447-468, 2014
    > doi: [10.1007/s10543-013-0455-z](https://doi.org/10.1007/s10543-013-0455-z)

"""
retract(::Tucker, ::Any, ::Any, ::PolarRetraction)

function retract!(
    ::Tucker, q::TuckerPoint, p::TuckerPoint{T,D}, x::TuckerTVector, ::PolarRetraction
) where {T,D}
    U = p.hosvd.U
    V = x.UÃá
    ‚Ñ≠ = p.hosvd.core
    ùîä = x.CÃá
    r‚Éó = size(‚Ñ≠)

    # Build the core tensor S and the factors [U·µà  V·µà]
    S = zeros(T, 2 .* size(‚Ñ≠))
    S[CartesianIndices(‚Ñ≠)] = ‚Ñ≠ + ùîä
    UQ = Matrix{T}[]
    for d in 1:D
        # We make the following adaptation to Kressner2014:
        # Fix the i'th term of the sum and replace V·µ¢ by Q·µ¢ R·µ¢.
        # We can absorb the R factor into the core by replacing V·µ¢ by Q·µ¢
        # and C (in the i'th term of the sum) by C √ó·µ¢ R·µ¢
        Q, R = qr(V[d])
        idxOffset = CartesianIndex(ntuple(i -> i == d ? r‚Éó[d] : 0, D))
        ‚Ñ≠_transf = fold(R * unfold(‚Ñ≠, d), d, size(‚Ñ≠))
        S[CartesianIndices(‚Ñ≠) .+ idxOffset] = ‚Ñ≠_transf
        push!(UQ, hcat(U[d], Matrix(Q)))
    end

    #Convert to truncated HOSVD of p + x
    hosvd_S = st_hosvd(S, r‚Éó)
    factors = UQ .* hosvd_S.U
    for i in 1:D
        q.hosvd.U[i] .= factors[i]
        q.hosvd.œÉ[i] .= hosvd_S.œÉ[i]
    end
    q.hosvd.core .= hosvd_S.core
    return q
end

function Base.show(io::IO, ::MIME"text/plain", ùíØ::Tucker{N,R,D,ùîΩ}) where {N,R,D,ùîΩ}
    return print(io, "Tucker(", N, ", ", R, ", ", ùîΩ, ")")
end
function Base.show(io::IO, ::MIME"text/plain", ùîÑ::TuckerPoint)
    pre = " "
    summary(io, ùîÑ)
    for d in eachindex(ùîÑ.hosvd.U)
        println(io, string("\nU factor ", d, ":"))
        su = sprint(show, "text/plain", ùîÑ.hosvd.U[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCore :")
    su = sprint(show, "text/plain", ùîÑ.hosvd.core; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    return print(io, pre, su)
end
function Base.show(io::IO, ::MIME"text/plain", x::TuckerTVector)
    pre = " "
    summary(io, x)
    for d in eachindex(x.UÃá)
        println(io, string("\nUÃá factor ", d, ":"))
        su = sprint(show, "text/plain", x.UÃá[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCÃá factor :")
    su = sprint(show, "text/plain", x.CÃá; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    return print(io, pre, su)
end
function Base.show(io::IO, mime::MIME"text/plain", ‚Ñ¨::CachedHOSVDBasis{ùîΩ,T,D}) where {ùîΩ,T,D}
    summary(io, ‚Ñ¨)
    print(" ‚âÖ")
    su = sprint(show, "text/plain", convert(Matrix{T}, ‚Ñ¨); context=io, sizehint=0)
    su = replace(su, '\n' => "\n ")
    return println(io, " ", su)
end

"""
    Base.size(::TuckerPoint)

The dimensions of a tensor of low multilinear rank
"""
Base.size(ùîÑ::TuckerPoint) = map(u -> size(u, 1), ùîÑ.hosvd.U)

#=
Modification of the ST-HOSVD from [Vannieuwenhoven2012]
This is the HOSVD of an approximation of ùîÑ, i.e. the core of this decomposition
is also in HOSVD format.
=#
function st_hosvd(ùîÑ, mlrank=size(ùîÑ))
    T = eltype(ùîÑ)
    D = ndims(ùîÑ)
    n‚Éó = size(ùîÑ)
    # Add type assertions to U and œÉ for type stability
    U::NTuple{D,Matrix{T}} = ntuple(d -> Matrix{T}(undef, n‚Éó[d], mlrank[d]), D)
    œÉ::NTuple{D,Vector{T}} = ntuple(d -> Vector{T}(undef, mlrank[d]), D)

    for d in 1:D
        r_d = mlrank[d]
        ùîÑ‚ÅΩ·µà‚Åæ = unfold(ùîÑ, d)
        # truncated SVD + incremental construction of the core
        UŒ£V·µÄ = svd(ùîÑ‚ÅΩ·µà‚Åæ)
        U[d] .= UŒ£V·µÄ.U[:, 1:r_d]
        œÉ[d] .= UŒ£V·µÄ.S[1:r_d]
        ùîÑ‚ÅΩ·µà‚Åæ = Diagonal(œÉ[d]) * UŒ£V·µÄ.Vt[1:r_d, :]
        # Reshape; compiler doesn't know the order of the result without type assertion
        m‚Éó::NTuple{D,Int} = tuple(mlrank[1:d]..., n‚Éó[(d + 1):D]...)
        ùîÑ = fold(ùîÑ‚ÅΩ·µà‚Åæ, d, m‚Éó)
    end

    # Make sure the truncated core is in "all-orthogonal" HOSVD format
    if mlrank ‚â† n‚Éó
        hosvd_core = st_hosvd(ùîÑ, mlrank)
        U = U .* hosvd_core.U
        ùîÑ = hosvd_core.core
        œÉ = hosvd_core.œÉ
    end

    return HOSVD{T,D}(U, ùîÑ, œÉ)
end

#Mode-k unfolding of the array ùîÑ of order D ‚â• k
function unfold(ùîÑ, k)
    d = ndims(ùîÑ)
    ùîÑ_ = permutedims(ùîÑ, vcat(k, 1:(k - 1), (k + 1):d))
    return reshape(ùîÑ_, size(ùîÑ, k), div(length(ùîÑ), size(ùîÑ, k)))
end

@doc raw"""
    zero_vector(::Tucker, A::TuckerPoint)

The zero element in the tangent space to A on the Tucker manifold
"""
function zero_vector!(::Tucker, X::TuckerTVector, ::TuckerPoint)
    for UÃá in X.UÃá
        fill!(UÃá, zero(eltype(UÃá)))
    end
    fill!(X.CÃá, zero(eltype(X.CÃá)))
    return X
end

# The standard implementation of allocate_result on vector-valued functions gives an element
# of the same type as the manifold point. We want a vector instead.
vector_result_fcns = [:get_vector, :inverse_retract, :project, :zero_vector]
for fun in vector_result_fcns
    @eval function ManifoldsBase.allocate_result(M::Tucker, f::typeof($(fun)), p, args...)
        return allocate_vector(M, p)
    end
end

function ManifoldsBase.allocate_result(M::Tucker, f::typeof(embed), p, args...)
    dims = representation_size(M)
    return Array{number_eltype(p),length(dims)}(undef, dims)
end
