
@doc raw"""
Tucker{N, R, D, ğ”½} <: AbstractManifold{ğ”½}

The manifold of $N_1 \times \dots \times N_D$ real-valued or complex-valued matrices of fixed multilinear rank
$(R_1, \dots, R_D).


[^Kressner2014]:
> Daniel Kressner, Michael Steinlechner, Bart Vandereycken: "Low-rank tensor completion by Riemannian optimization"
> BIT Numerical Mathematics, 54(2), pp. 447-468, 2014
> doi: [10.1007/s10543-013-0455-z](https://doi.org/10.1007/s10543-013-0455-z)
"""
struct Tucker{N, R, D, ğ”½} <: AbstractManifold{ğ”½} end
function Tucker(nâƒ— :: NTuple{D, Int}, râƒ— :: NTuple{D, Int}, field :: AbstractNumbers = â„) where D
    @assert isValidTuckerRank(nâƒ—, râƒ—)
    Tucker{nâƒ—, râƒ—, D, field}()
end

"""
    HOSVD{T, D}

Higher-order singular value decomposition of an order D tensor with eltype T 
fields: 
* U: singular vectors of the unfoldings
* core: core tensor
* Ïƒ : singular values of the unfoldings
"""
struct HOSVD{T, D}
    U    :: NTuple{D, Matrix{T}}
    core :: Array{T, D}
    Ïƒ    :: NTuple{D, Vector{T}}
end

struct HOSVDRetraction <: AbstractRetractionMethod end

"""
    TuckerPoint{T, D} 

An order D tensor of fixed multilinear rank and entries of type T.
"""
struct TuckerPoint{T, D} <: AbstractManifoldPoint
    hosvd :: HOSVD{T, D}
end
function TuckerPoint(core :: AbstractArray{T, D}, factors :: Vararg{MtxT, D}) where {T, D, MtxT <: AbstractMatrix{T}}
    # Take the QR decompositions of the factors and multiply the R factors into the core
    qrfacs  = qr.(factors)
    Q       = map(qrfac -> qrfac.Q, qrfacs)
    R       = map(qrfac -> qrfac.R, qrfacs)
    coreâ€²   = reshape(Kronecker.:âŠ—(reverse(R)...) * vec(core), size(core))
    
    # Convert to HOSVD format by taking the HOSVD of the core
    decomp   = st_hosvd(coreâ€²)
    factorsâ€² = Q .* decomp.U
    TuckerPoint(HOSVD{T, D}(factorsâ€², decomp.core, decomp.Ïƒ))
end
function TuckerPoint(A :: AbstractArray, mlrank :: NTuple{D, Int}) where {D}
    #TODO  
    error("Not implemented")
end

@doc raw"""
    TuckerTVectort{T, D} <: TVector

Tangent space to the Tucker manifold at `x = (U_1,\dots,U_D) â‹… \mathcal{C}`. This vector is represented as
```math 
(U_1,\dots,U_D) \cdot \dot{\mathcal{C}} + \sum_{d=1}^D (U_1,\dots,U_{d-1},\dot{U}_d,U_{d+1},\dots,U_D) \cdot \mathcal{C}
````
where $\dot_{U}_d^\mathrm{H} U_d = 0$
"""
struct TuckerTVector{T, D} <: TVector
    CÌ‡ :: Array{T, D}
    UÌ‡ :: NTuple{D, Matrix{T}}
end

"""
    HOSVDBasis{T, D}

A implicitly stored basis of the tangent space to the Tucker manifold.
If ğ”„ = (UÂ¹ âŠ— ... âŠ— Uá´°) C is a HOSVD, then this basis is defined as follows:

â„¬ = {(UÂ¹ âŠ— ... âŠ— Uá´°) eáµ¢} âˆª {(UÂ¹ âŠ— ... âŠ— 1/Ïƒ[d][j] UáµˆâŠ¥ eáµ¢ eâ±¼áµ€ âŠ— ... âŠ— Uá´°) C}

See also:
[^Dewaele2021]
> Nick Dewaele, Paul Breiding, Nick Vannieuwenhoven, "The condition number of many tensor decompositions is invariant under Tucker compression"
#TODO arXiv
"""
struct HOSVDBasis{T, D}
	point :: TuckerPoint{T, D}
    UâŠ¥    :: NTuple{D, Matrix{T}}
end
CachedHOSVDBasis{ğ”½, T, D} = CachedBasis{ğ”½,DefaultOrthonormalBasis{ğ”½, TangentSpaceType},HOSVDBasis{T, D}}

âŠ—á´¿(a...) = Kronecker.:âŠ—(reverse(a)...)

Base.:*(s::Number, x::TuckerTVector) = TuckerTVector(s * x.CÌ‡, s .* x.UÌ‡)
Base.:*(x::TuckerTVector, s::Number) = TuckerTVector(x.CÌ‡ * s, x.UÌ‡ .* s)
Base.:/(x::TuckerTVector, s::Number) = TuckerTVector(x.CÌ‡ / s, x.UÌ‡ ./ s)
Base.:\(s::Number, x::TuckerTVector) = TuckerTVector(s \ x.CÌ‡, s .\ x.UÌ‡)
Base.:+(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÌ‡ + y.CÌ‡, x.UÌ‡ .+ y.UÌ‡)
Base.:-(x::TuckerTVector, y::TuckerTVector) = TuckerTVector(x.CÌ‡ - y.CÌ‡, x.UÌ‡ .- y.UÌ‡)
Base.:-(x::TuckerTVector) = TuckerTVector(-x.CÌ‡, map(-, x.UÌ‡))
Base.:+(x::TuckerTVector) = TuckerTVector(x.CÌ‡, x.UÌ‡)
Base.:(==)(x :: TuckerTVector, y :: TuckerTVector) = (x.CÌ‡ == y.CÌ‡) && (x.UÌ‡ .== y.UÌ‡)

allocate(p :: TuckerPoint) = allocate(p, number_eltype(p))
function allocate(p::TuckerPoint, ::Type{T}) where T
    # This is not necessarily a valid HOSVD it's not worth computing the HOSVD
    # just for allocation
    TuckerPoint(HOSVD(allocate(p.hosvd.U, T), allocate(p.hosvd.core, T), allocate(p.hosvd.Ïƒ, T)))
end
allocate(x :: TuckerTVector) = allocate(x, number_eltype(x))
function allocate(x::TuckerTVector, ::Type{T}) where T
    TuckerTVector(allocate(x.CÌ‡, T), allocate(x.UÌ‡, T))
end

"""
An orthonormal basis for the tangent space to the Tucker manifold at a point ğ”„, represented as a matrix
"""
function Base.convert(::Type{Matrix{T}}, basis :: CachedHOSVDBasis{ğ”½, T, D}) where {ğ”½, T, D}
    ğ”„    = basis.data.point
    UâŠ¥   = basis.data.UâŠ¥
    U    = ğ”„.hosvd.U
    Ïƒ    = ğ”„.hosvd.Ïƒ
    â„­    = ğ”„.hosvd.core
    râƒ—    = size(â„­)
    nâƒ—    = size(ğ”„)

    J = Matrix{T}(undef, prod(nâƒ—), manifold_dimension(Tucker(nâƒ—, râƒ—)))
    # compute all possible âˆ‚ğ”„â•±âˆ‚â„­
    J[:, 1:prod(râƒ—)] = âŠ—á´¿(U...)
    # compute all possible âˆ‚ğ”„â•±âˆ‚U[d] for d = 1,...,D
    nextcolumn = prod(râƒ—)
    for d = 1:D
        Udáµ€ğ”„â½áµˆâ¾ :: Matrix{T} = unfold(â„­, d) * âŠ—á´¿(U[1:d-1]..., U[d+1:end]...)'
        for i = 1:size(UâŠ¥[d], 2), j = 1:râƒ—[d]
            âˆ‚ğ”„áµ¢â±¼â½áµˆâ¾ = 1/Ïƒ[d][j] * UâŠ¥[d][:,i] * Udáµ€ğ”„â½áµˆâ¾[j,:]'
            âˆ‚ğ”„áµ¢â±¼    = fold(âˆ‚ğ”„áµ¢â±¼â½áµˆâ¾, d, nâƒ—)
            J[:,nextcolumn += 1] = vec(âˆ‚ğ”„áµ¢â±¼)
        end
    end
    J
end
Base.convert(::Type{Matrix}, basis :: CachedHOSVDBasis{ğ”½, T, D}) where {ğ”½, T, D} = convert(Matrix{T}, basis)

function Base.convert(::Type{Array{T,D}}, ğ”„ :: TuckerPoint{TA, D}) where {T, TA <: T, D}
    reshape(âŠ—á´¿(ğ”„.hosvd.U...) * vec(ğ”„.hosvd.core), size(ğ”„))
end
Base.convert(::Type{Array}, ğ”„ :: TuckerPoint{T, D}) where {T,D} = convert(Array{T,D}, ğ”„)
function Base.convert(::Type{Array{T,D}}, ğ”„ :: TuckerPoint{TA, D}, X :: TuckerTVector) where {T, TA <: T, D}
    X_ambient = âŠ—á´¿(ğ”„.hosvd.U...) * vec(X.CÌ‡)
    for d = 1:D
        X_ambient += âŠ—á´¿(ntuple(d_ -> d_ == d ? X.UÌ‡[d_] : ğ”„.hosvd.U[d_], D)...) * vec(ğ”„.hosvd.core)
    end
    reshape(X_ambient, size(ğ”„))
end
function Base.convert(::Type{Array}, ğ”„ :: TuckerPoint{T, D}, X :: TuckerTVector) where {T,D}
    convert(Array{T,D}, ğ”„, X)
end

Base.copy(x :: TuckerTVector) = TuckerTVector(copy(x.CÌ‡), map(copy, x.UÌ‡))

"""
Inverse of the k'th unfolding of a size nâ‚ Ã— ... Ã— n_D tensor
"""
function fold(ğ”„â™­ :: AbstractMatrix{T}, k, nâƒ— :: NTuple{D, Int}) :: Array{T, D} where {T, D, Int}
    @assert 1 â‰¤ k â‰¤ D
    @assert size(ğ”„â™­, 1) == nâƒ—[k]

    # (compiler doesn't know we are reshaping back into order D array without type assertion)
    size_pre_permute :: NTuple{D, Int} = (nâƒ—[k], nâƒ—[1:k-1]..., nâƒ—[k+1:D]...)
    perm :: NTuple{D, Int} = ((2:k)..., 1, (k+1:D)...)
    permutedims(reshape(ğ”„â™­, size_pre_permute), perm)
end

function get_basis(:: Tucker, ğ”„ :: TuckerPoint, basisType::DefaultOrthonormalBasis{ğ”½, TangentSpaceType}) where ğ”½
    D = ndims(ğ”„)
    nâƒ— = size(ğ”„) 
    râƒ— = size(ğ”„.hosvd.core) 

    U = ğ”„.hosvd.U
    UâŠ¥ = ntuple(d -> Matrix(qr(I - U[d]*U[d]', Val(true)).Q)[:,1:nâƒ—[d]-râƒ—[d]], D)

    basis = HOSVDBasis(ğ”„, UâŠ¥)
	CachedBasis(basisType, basis)
end

function get_coordinates(::Tucker, ğ”„, X, â„¬::CachedBasis)
    coords = vec(X.CÌ‡)
    for d = 1:length(X.UÌ‡)
        coord_mtx = (â„¬.data.UâŠ¥[d] \ X.UÌ‡[d]) * Diagonal(ğ”„.hosvd.Ïƒ[d])
        coords = vcat(coords, vec(coord_mtx'))
    end
    coords
end

function get_vector(::Tucker, ğ”„ :: TuckerPoint, Î¾ :: AbstractVector{T}, â„¬ :: CachedHOSVDBasis) where T
    U = ğ”„.hosvd.U
    â„­ = ğ”„.hosvd.core
    Ïƒ = ğ”„.hosvd.Ïƒ
    UâŠ¥ = â„¬.data.UâŠ¥
    D = ndims(â„­)
    râƒ— = size(â„­)
    nâƒ— = size(ğ”„)

    # split Î¾ into Î¾_core and Î¾U so that vcat(Î¾_core, Î¾U...) == Î¾
    Î¾_core     = Î¾[1:length(â„­)]
    Î¾U         = Vector{T}[]
    nextcolumn = length(â„­) + 1
    for d = 1:D
        numcols = râƒ—[d]*(nâƒ—[d] - râƒ—[d])
        push!(Î¾U, Î¾[nextcolumn:nextcolumn + numcols - 1])
        nextcolumn += numcols
    end

    # Construct âˆ‚U[d] by plugging in the definition of
    #    our orthonormal basis:
    # V[d] = âˆ‚U[d] = âˆ‘áµ¢â±¼ { Î¾[d]áµ¢â±¼ (Ïƒ[d]â±¼)â»Â¹ UâŠ¥[d] ğáµ¢ ğâ±¼áµ€ }
    #      = âˆ‘â±¼ (Ïƒ[d]â±¼)â»Â¹ UâŠ¥[d] ( âˆ‘áµ¢ Î¾[d]áµ¢â±¼  ğáµ¢) ğâ±¼áµ€
    âˆ‚U = similar.(U)
    for d = 1:D
        # Assuming Î¾ = [Î¾â‚â‚, ..., Î¾â‚â±¼, ..., Î¾áµ¢â‚, ..., Î¾áµ¢â±¼, ..., ], we can
        # reshape Î¾U[d] into a matrix with row indices i and column indices j
        grid = transpose(reshape(Î¾U[d], râƒ—[d], nâƒ—[d] - râƒ—[d]))
        # Notice that âˆ‘áµ¢ Î¾áµˆáµ¢â±¼ğáµ¢ = grid[:,j].
        # This means V[d] = UâŠ¥[d] * grid * Diagonal(Ïƒ[d])â»Â¹
        âˆ‚U[d][:,:] = UâŠ¥[d] * grid * Diagonal(1 ./ Ïƒ[d])
    end

    âˆ‚C = reshape(Î¾_core, size(â„­))
    TuckerTVector(âˆ‚C, âˆ‚U)
end

"""
    isValidTuckerRank(nâƒ—, râƒ—)

Determines whether there are tensors of dimensions nâƒ— with multilinear rank râƒ—
"""
isValidTuckerRank(nâƒ—, râƒ—) = all(râƒ— .â‰¤ nâƒ—) && all(ntuple(i -> râƒ—[i] â‰¤ prod(râƒ—) Ã· râƒ—[i], length(râƒ—)))

manifold_dimension(:: Tucker{nâƒ—, râƒ—}) where {nâƒ—, râƒ—} = prod(râƒ—) + sum(râƒ— .* (nâƒ— .- râƒ—))

Base.ndims(:: TuckerPoint{T, D}) where {T,D} = D

number_eltype(p::TuckerPoint{T,D}) where {T, D} = T
number_eltype(x::TuckerTVector{T,D}) where {T, D} = T

function retract!(::Tucker, q::TuckerPoint, p::TuckerPoint{T, D}, x::TuckerTVector, ::HOSVDRetraction) where {T, D}
    U = p.hosvd.U 
    V = x.UÌ‡
    â„­ = p.hosvd.core
    ğ”Š = x.CÌ‡
    râƒ— = size(â„­)

    # Build the core tensor S and the factors [Uáµˆ  Váµˆ]
    S = zeros(T, 2 .* size(â„­))
    S[CartesianIndices(â„­)] = â„­ + ğ”Š
    UQ = Matrix{T}[]
    for d = 1:D
        # We make the following adaptation to Kressner2014:
        # Fix the i'th term of the sum and replace Váµ¢ by Qáµ¢ Ráµ¢.
        # We can absorb the R factor into the core by replacing Váµ¢ by Qáµ¢
        # and C (in the i'th term of the sum) by C Ã—áµ¢ Ráµ¢
        Q, R = qr(V[d])
        idxOffset = CartesianIndex(ntuple(i -> i == d ? râƒ—[d] : 0, D))
        â„­_transf  = fold(R * unfold(â„­, d), d, size(â„­))
        S[CartesianIndices(â„­) .+ idxOffset] = â„­_transf
        push!(UQ, hcat(U[d], Matrix(Q)))
    end

    #Convert to truncated HOSVD of p + x
    hosvd_S = st_hosvd(S, râƒ—)
    factors = UQ .* hosvd_S.U 
    for i in 1:D
        q.hosvd.U[i] .= factors[i]
        q.hosvd.Ïƒ[i] .= hosvd_S.Ïƒ[i]
    end
    q.hosvd.core .= hosvd_S.core 
    q
end

function Base.show(io::IO, ::MIME"text/plain", ğ’¯::Tucker{N,R,D,ğ”½}) where {N,R,D,ğ”½}
    print(io, "Tucker(", N, ", ", R, ", ", ğ”½, ")")
end
function Base.show(io::IO, ::MIME"text/plain", ğ”„::TuckerPoint)
    pre = " "
    summary(io, ğ”„)
    for d in eachindex(ğ”„.hosvd.U)
        println(io, string("\nU factor ", d, ":"))
        su = sprint(show, "text/plain", ğ”„.hosvd.U[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCore :")
    su = sprint(show, "text/plain", ğ”„.hosvd.core; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    print(io, pre, su)
end
function Base.show(io::IO, ::MIME"text/plain", x::TuckerTVector)
    pre = " "
    summary(io, x)
    for d in eachindex(x.UÌ‡)
        println(io, string("\nUÌ‡ factor ", d, ":"))
        su = sprint(show, "text/plain", x.UÌ‡[d]; context=io, sizehint=0)
        su = replace(su, '\n' => "\n$(pre)")
        println(io, pre, su)
    end
    println(io, "\nCÌ‡ factor :")
    su = sprint(show, "text/plain", x.CÌ‡; context=io, sizehint=0)
    su = replace(su, '\n' => "\n$(pre)")
    print(io, pre, su)
end
function Base.show(io :: IO, mime::MIME"text/plain", â„¬ :: CachedHOSVDBasis{ğ”½, T, D}) where {ğ”½, T, D} 
    summary(io, â„¬)
    print(" â‰…")
    su = sprint(show, "text/plain", convert(Matrix{T}, â„¬); context=io, sizehint=0)
    su = replace(su, '\n' => "\n ")
    println(io, " ", su)
end


Base.size(ğ”„ :: TuckerPoint) = map(u -> size(u,1), ğ”„.hosvd.U)

"""
    st_hosvd(ğ”„, mlrank=size(ğ”„)) 

The sequentially truncated HOSVD, as in 
[^Vannieuwenhoven2012]
> Nick Vannieuwenhoven, Raf Vandebril, Karl Meerbergen: "A new truncation strategy for the higher-order singular value decomposition"
> SIAM Journal on Scientific Computing, 34(2), pp. 1027-1052, 2012
> doi: [10.1137/110836067](https://doi.org/10.1137/110836067)
"""
function st_hosvd(ğ”„, mlrank=size(ğ”„)) 
    T = eltype(ğ”„)
    D = ndims(ğ”„)
    nâƒ— = size(ğ”„)
    U :: Vector{Matrix{T}} = collect(ntuple(d -> Matrix{T}(undef, nâƒ—[d], mlrank[d]), D))
    Ïƒ :: Vector{Vector{T}} = [Vector{T}(undef, mlrank[d]) for d = 1:D]

    for d = 1:D
        # unfold
        r_d  = mlrank[d]
        ğ”„â½áµˆâ¾ = unfold(ğ”„, d)
        # truncated SVD + incremental construction of the core
        UÎ£Váµ€ = svd(ğ”„â½áµˆâ¾)
        U[d] = UÎ£Váµ€.U[:,1:r_d]
        Ïƒ[d] = UÎ£Váµ€.S[1:r_d]
        ğ”„â½áµˆâ¾ = Diagonal(Ïƒ[d]) * UÎ£Váµ€.Vt[1:r_d,:]
        # reshape back into a tensor
        # (compiler doesn't know we are reshaping back into order D array without type assertion)
        mâƒ— :: NTuple{D, Int} = tuple(mlrank[1:d]..., nâƒ—[d+1:D]...)
        ğ”„ = fold(ğ”„â½áµˆâ¾, d, mâƒ—)
    end

    HOSVD{T, D}(tuple(U...), ğ”„, tuple(Ïƒ...))
end

"""
	unfold(ğ”„, k)

Mode-k unfolding of the array ğ”„ of order d â‰¥ k
"""
function unfold(ğ”„, k)
	d  = ndims(ğ”„)
	ğ”„_ = permutedims(ğ”„, vcat(k, 1:k-1, k+1:d))
	reshape(ğ”„_, size(ğ”„, k), div(length(ğ”„), size(ğ”„, k)))
end


